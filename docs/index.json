[{"body":"Implementation Source Download application artifacts from here.\nDownload GraphBuilder user extensions from here\nInstallation Open TIBCO Flogo® Enterprise 2.8.1 studio and upload required user extensions (builder.zip, tgdb.zip and tools.zip)\nCreate an empty application for Airline\nImport application from the pre-configured Airline application descriptor\nFind and select descriptor (airline.json) from download folder\nIgnore waning just click \u0026ldquo;Import All\u0026rdquo;\nAirline application with two data flow (flight and pnr) is imported\nCheck connection tab to see two connections to be fixed\nSelect TGDB connection and edit it\nMake configuration meet your TIBCO® Graph Database setup then click \u0026ldquo;Connect\u0026rdquo; to save it\nSame to the Graph connection but just click \u0026ldquo;Connect\u0026rdquo; since graph model has been correctly set\n This example is created in TIBCO Flogo® Enterprise 2.8.1 studio.\n ","excerpt":"Implementation Source Download application artifacts from here.\nDownload GraphBuilder user …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/airline/","title":"Airline"},{"body":" Graph Connector : A Graph connector is a component which hosts your graph model for sharing graph model among graph construction related activity. Activities which connect to the same Graph connector would share same graph model (data schema)  Here is the schema of graph model\n{\r\u0026quot;$schema\u0026quot;: \u0026quot;http://json-schema.org/draft-04/schema#\u0026quot;,\r\u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\r\u0026quot;properties\u0026quot;: {\r\u0026quot;nodes\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;array\u0026quot;,\r\u0026quot;items\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\r\u0026quot;properties\u0026quot;: {\r\u0026quot;name\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\r},\r\u0026quot;key\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;array\u0026quot;,\r\u0026quot;items\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\r}\r},\r\u0026quot;attributes\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;array\u0026quot;,\r\u0026quot;items\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\r\u0026quot;properties\u0026quot;: {\r\u0026quot;name\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\r},\r\u0026quot;type\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\r}\r},\r\u0026quot;required\u0026quot;: [\r\u0026quot;name\u0026quot;,\r\u0026quot;type\u0026quot;\r]\r}\r}\r},\r\u0026quot;required\u0026quot;: [\r\u0026quot;name\u0026quot;,\r\u0026quot;key\u0026quot;,\r\u0026quot;attributes\u0026quot;\r]\r}\r},\r\u0026quot;edges\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;array\u0026quot;,\r\u0026quot;items\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\r\u0026quot;properties\u0026quot;: {\r\u0026quot;to\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\r},\r\u0026quot;name\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\r},\r\u0026quot;from\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\r},\r\u0026quot;attributes\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;array\u0026quot;,\r\u0026quot;items\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;object\u0026quot;,\r\u0026quot;properties\u0026quot;: {\r\u0026quot;name\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\r},\r\u0026quot;type\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;string\u0026quot;\r}\r}\r}\r}\r},\r\u0026quot;required\u0026quot;: [\r\u0026quot;from\u0026quot;,\r\u0026quot;name\u0026quot;,\r\u0026quot;to\u0026quot;,\r\u0026quot;attributes\u0026quot;\r]\r}\r}\r}\r}\r   BuildGraph Activity A BuildGraph activity must connect to a Graph connector so it can build its input data schema from the graph model which is hosted in that Graph connector. BuildGraph activity transform the input data to graph entities (nodes, edges and their attributes) based on the graph model     GraphToFile A GraphToFile activity takes graph entities (nodes and edges) from BuildGraph and writes them to a file. It's an useful utility for troubleshooting    ","excerpt":"Graph Connector : A Graph connector is a component which hosts your graph model for sharing graph …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder/","title":"GraphBuilder"},{"body":"Let's start with building a graph model for Northwind dataset. In connection tab select Graph to host graph model for your flogo application.\nIn the diaog box\n Set model name Select \u0026ldquo;Local File\u0026rdquo; select and upload northwind_model.json (Northwind model descriptor) from your download folder Click connect  The Northwind model descriptor file has attached to your graph model\nNow let's select \u0026ldquo;Apps\u0026rdquo; tab and click \u0026ldquo;Create\u0026rdquo; button to start building your first allication\nName the application \u0026ldquo;Northwind\u0026rdquo; then create it\nSelect create to build it from scratch\nFlogo® Enterprise studio brings you to the dialog for creating the first flow. According to Northwind dataset we have, we are going to create five flows to process data from customers.csv, suppliers.csv, employees.csv, categories.csv and products.csv respectively. We'll start from Building the customer data flow.\nIn the empty flow panel click \u0026ldquo;Flow Inputs \u0026amp; Outputs\u0026rdquo; verticle bar to generate data schema for current flow.\nThe flow starts from processing CSV data rows from a file one line each time (we'll set it up in FileReader Trigger later). Just set a sample of useful data fields from incoming data. In the sample \u0026ldquo;FileContent\u0026rdquo; field represents a row of CSV data and \u0026ldquo;LineNumber\u0026rdquo; filelds is current \u0026ldquo;sequence number\u0026rdquo; of that row.\nAfter clik \u0026ldquo;Save\u0026rdquo; buttom the schema generator of studio converts data sample to its schema definition.\nLet's add a trigger (data source of the flow) by clicking \u0026ldquo;+\u0026rdquo; buttom on the left and select GraphBuilder_Tools -\u0026gt; FileReader trigger.\nFilling the \u0026ldquo;Trigger Settings\u0026rdquo;\n Filename : point to the customers.csv in your download folder Asynchronous : set it true so all triggers for different data could run simutanously Emit per Line : set it true to make sure each time only one row of data get sent to flow Max Number of Line : set to negative means no limit.  Click \u0026ldquo;Save\u0026rdquo; after you finish it\nNow switch to \u0026ldquo;Map to Flow Inputs\u0026rdquo; and make following mapping\n FileContent (defined in schema) -\u0026gt; $trigger.FileContent LineNumber (defined in schema) -\u0026gt; $trigger.LineNumber  Click \u0026ldquo;Save\u0026rdquo; button\nBack to flow and adding first activity to the flow. Select GraphBuilder_Tools -\u0026gt; CSVParser for converting CSV text to system object.\nFilling Settings\n Date Format Sample : 2006-01-02 (Data format setup for underlining GOLang code) Serve Graph Data : set to false since we are not using it Output Field Names : One line of setting for each data column. AttributeName is the attribute name in generated system object and CSVFieldName is the column name in CSV data row. Set optional to \u0026ldquo;false\u0026rdquo; for all key element fields. Click \u0026ldquo;Save\u0026rdquo; after finish configuring each line. First Row is Heade : Set it true since the data file we use has a header  Click \u0026ldquo;Save\u0026rdquo; button\nSwitch to Inputs and map current input data to output data from upstream\n CSVString -\u0026gt; $flow.FileContent SequenceNumber -\u0026gt; $flow.LineNumber  Click \u0026ldquo;Save\u0026rdquo; when finishing it\nNow the data has been transform to the system object which could be recognized by the system. The next step is to convert plain object data to graph entities (nodes, edges and their attributes). We are going to use the core activity clled \u0026ldquo;BuildGraph\u0026rdquo; to perform this tranformation.\nLet's select GraphBuilder -\u0026gt; Bruild Graph and configue it.\nFilling setting\n Graph Model : Select \u0026ldquo;Northwind\u0026rdquo; connector which we just created. The \u0026ldquo;Northwind\u0026rdquo; graph model now associated with this activity which means BuildGraph activity take \u0026ldquo;Northwind\u0026rdquo; graph model to build the structure of its input data schema. You would see this when we setup \u0026ldquo;Inputs\u0026rdquo; data mapping later. Allow Null Key : set it \u0026ldquo;true\u0026rdquo; will make it generate node, edge even their primary key contains null elements. Batch Mode : set it \u0026ldquo;false\u0026rdquo; since we process one data each time. Pass Through Fields : (leave it empty) Modify Size of Instances : (leave it empty, will use it in Employee data setup)  Click \u0026ldquo;Save\u0026rdquo; button\nBefore we can map the input data, let's a take look of the output schema of \u0026ldquo;CSVParser\u0026rdquo; (it's the upstream data for current \u0026ldquo;BuildGraph\u0026rdquo; activity). Since \u0026ldquo;CSVParser\u0026rdquo; has ability to handle multiple CSV rows, the output data structure is an array of object not just a single object.\nFor procees the incoming array type of data, we need to turn on the iterator to iterate through upstream output data. Even there is only one element in the array for the current case. Following screenshot shows how to do it.\nFor mapping the input data you may notice that 1. the \u0026ldquo;Northwind\u0026rdquo; graph model has been brought to this activity as input schema, 2. The mapping target is not to \u0026ldquo;CSVParser\u0026rdquo; anymore but the local interation. For the data coming from customers.csv you can populate more than one type of nodes which are deinfed in Northwind graph. Here is the nodes (Customer, Company and Region) which will be set.\nCustomer node\n _skipCondition -\u0026gt; null==$iteration[value].CustomerID CustomerID -\u0026gt; $iteration[value].CustomerID CustomerName -\u0026gt; $iteration[value].CustomerName ContactName -\u0026gt; $iteration[value].ContactName ContactTitle -\u0026gt; $iteration[value].ContactTitle City -\u0026gt; $iteration[value].City RegionName -\u0026gt; $iteration[value].RegionName RegionCode -\u0026gt; $iteration[value].RegionCode Country -\u0026gt; $iteration[value].Country Phone -\u0026gt; $iteration[value].Phone Fax -\u0026gt; $iteration[value].Fax  Company node\n _skipCondition -\u0026gt; null==$iteration[value].CompanyID CompanyID -\u0026gt; $iteration[value].CompanyID CompanyName -\u0026gt; $iteration[value].CompanyName  Region node\n RegionName -\u0026gt; $iteration[value].RegionName Country -\u0026gt; $iteration[value].Country  You don't have to setup mapping for edge if you don't have attribute need to be setup for them (we don't configue \u0026ldquo;label\u0026rdquo; attribute for edges now since TGDB doesn't need it). BuildGraph activity is going to use the edge definded in graph model to create edge between nodes automatically.\nAfter we convert data to graph entities we can insert them to TIBCO® Graph Database. Let's create TIBCO® Graph Database connection first. In \u0026ldquo;Connections\u0026rdquo; tab select Add Connection -\u0026gt; TGDB Connector\nIn the diaog box filling following information\n Connection name (for example \u0026ldquo;TGDB\u0026rdquo;) TGDB Server URL Username Password Keep Connection Alive : select \u0026ldquo;true\u0026rdquo;  Click \u0026ldquo;Connect\u0026rdquo; button\nNow back to application's \u0026ldquo;Customer Data\u0026rdquo; flow to add TGDB activity. Slect GraphBuilder_TGDB -\u0026gt; TGDBUpsert.\nFilling Setting for\n TGDB connection : Select the \u0026ldquo;TGDB\u0026rdquo; Connection we just created Set Allow empty sting key to true (so a node with empty string key still get inserted)  Click \u0026ldquo;Save\u0026rdquo;\nMap input data\n Graph{} - $activity[BuildGraph].Graph{}  Since the Graph object is immutable, you are not allowed to access the detail of its internal structure.\nYou can insert a built-in \u0026ldquo;Log\u0026rdquo; activity by following steps: Make room for \u0026ldquo;Log\u0026rdquo; activity by shifting activities one position to the right.\nAdd \u0026ldquo;Log\u0026rdquo; activity by select Default -\u0026gt; Log\nSetup message for priniting (you can apply built-in fuctions to incoming data fields)\n message : string.concat(string.tostring($flow.LineNumber), \u0026quot; - \u0026ldquo;, $flow.FileContent)  You can write the entities (which are generated by BuildGraph activity) to file by adding GraphBuilder -\u0026gt; GraphtoFile activity\nSpecify the output folder and filename for GraphtoFile activity\nInput data is and only can be Graph. The input setup same as TGDBUpsert\nCongradulations you have finish the first data flow for the application\nNow you can follow the same steps to finish all the rest of flows\nWhen you work on \u0026ldquo;Employee flow\u0026rdquo;, please pay attention to following steps.\nIn employee data there are two fields called EmployeeID and ReportTo each of them represents one indivisual employee. It implies that from the infomation of one employee data we can populate two employee nodes. One for empoyee himself/herself and the other one for his/her manager. We have to incresae the instance of employee node for such data mapping.\n Modify size of instances : Add one entry for \u0026ldquo;Employee\u0026rdquo; node and make the number of instances to 2  Click \u0026ldquo;Save\u0026rdquo;\nSwitch to Inputs you will see two employee nodes appears (Employee0 and Employee1). Let's make employee0 the employee (not manager) so all data can be populate to this node.\nWe make the emplyee1 node represent the manager of employee0 node so the only information we have for it (in the data) is \u0026ldquo;ReportTo\u0026rdquo; which will populate employee1's EmployeeID.\nThen we need to tell BuildGrap activity the relation between employee0 and employee1.\nNow we can test out Northwind application by sending data to it then we'll verify if data get inserted to TIBCO® Graph Database server\nFor building Northwind flogo application\n In project click \u0026ldquo;Build\u0026rdquo; button Select the build target OS (in my case Darwin/amd64) then click to build  Once finished you can get your executable (Northwind-darwin_amd64) in your browser download folder\nThen we need to setup a TIBCO® Graph Database. Currently Project GraphBuilder \u0026ldquo;only\u0026rdquo; support TIBCO® Graph Database 2.0.1 (both Enterprise Edition and Community Edition are supported). You can get a Community version from here.\nFollow instructions in the download file to install TIBCO® Graph Database server then copy artifacts from your download folder\n Northwind/tgdb/northwind -\u0026gt; tgdb/2.0/examples Northwind/tgdb/init_northwind_with_data_definition.sh -\u0026gt; tgdb/2.0/bin/ Northwind/tgdb/run_northwind.sh -\u0026gt; tgdb/2.0/bin/  In terminal switch to tgdb/2.0/bin folder then\n execute ./init_northwind_with_data_definition.sh to initialize tgdb with Northwind schema   execute ./run_northwind.sh to run tgdb server  Open a new terminal and switch to the folder which contains Northwind appliction executable (Northwind-darwin_amd64).\n Change Northwind-darwin_amd64's permission to executable Run Northwind-darwin_amd64  Open a new terminal and switch to TIBCO® Graph Database bin folder\n run tgdb-admin make query to get all categories  We've proved that data has been inserted to TIBCO® Graph Database server\n","excerpt":"Let's start with building a graph model for Northwind dataset. In connection tab select Graph to …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/labs/lab-1/","title":"Lab1 - CSV"},{"body":"Implementation Source sDownload application artifacts from here.\nDownload GraphBuilder user extensions from here\nInstallation Open TIBCO Flogo® Enterprise 2.8.1 studio and upload required user extensions (builder.zip, sse.zip, tgdb.zip and tools.zip)\nFollow the Airline example to continue importing application\nCreate application from scratch see labs\n This example is created in TIBCO Flogo® Enterprise 2.8.0 studio.\n ","excerpt":"Implementation Source sDownload application artifacts from here.\nDownload GraphBuilder user …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/northwind/","title":"Northwind"},{"body":"Using GraphBuilder you are able to build your own application to\n Transform your data to desirded graph structure based upon your graph model. Insert graph data into many major graph databases in the marcket (include TIBCO® Graph Database, Dgraph, Neo4j and Janusgraph). Query and delete graph data against TIBCO® Graph Database  ","excerpt":"Using GraphBuilder you are able to build your own application to\n Transform your data to desirded …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/overview/","title":"Overview"},{"body":" Download latest TIBCO Flogo® Enterprise from here here Download GraphBuilder user extensions here import GraphBuilder user extensions to TIBCO Flogo® Enterprise studio (for detail, see instructions in following Labs) Enjoy it!  ","excerpt":" Download latest TIBCO Flogo® Enterprise from here here Download GraphBuilder user extensions here …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/getting-started/","title":"Getting Started"},{"body":"Implementation Source Download application artifacts from here.\nDownload GraphBuilder user extensions from here\nInstallation Open TIBCO Flogo® Enterprise 2.8.1 studio and upload required user extensions (builder.zip, tgdb.zip and tools.zip)\nFollow the Airline example to continue importing application\n This example is created in TIBCO Flogo® Enterprise 2.8.1 studio.\n ","excerpt":"Implementation Source Download application artifacts from here.\nDownload GraphBuilder user …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/hierachy/","title":"Hierachy"},{"body":"Create a new flogo application called \u0026ldquo;TGDB_RESTful_Service\u0026rdquo;\nClick \u0026ldquo;+ Create\u0026rdquo; button to construct it from scratch\nCreate the first flow for querying metadata\nDefine the data schema for the input of current flow sample data (note : queryType in string data type).\n queryType : the value could be \u0026ldquo;metadata\u0026rdquo;, \u0026ldquo;edgetypes\u0026rdquo; or \u0026ldquo;nodetypes\u0026rdquo; (metadata querying flow)  Save sample data would envoke schema builder to generate schema definition of it\nDefine output schema for current flow by by pasting sample output data\n Content : contains the data of query result Success : true means query go through without error Code : error code Message : error message  Click \u0026ldquo;Save\u0026rdquo; button\nClicking \u0026ldquo;Save\u0026rdquo; button triggers schema definition generation\nAdd a trigger to receive HTTP request by clicking \u0026ldquo;+\u0026rdquo; -\u0026gt; \u0026ldquo;ReceiveHTTPMessage\u0026rdquo;\nSelect GET, enter resource path \u0026ldquo;/tgdb/{queryType}\u0026rdquo; then click \u0026ldquo;Finish\u0026rdquo;\nNow we have a trigger with HTTP GET methods and listen on port 9999)\nClick the icon of trigger to map incoming query data to flow input data\nIn \u0026ldquo;Reply Settings\u0026rdquo; set reply schema make it same as flow output data schema\nIn \u0026ldquo;Map from flow outputs\u0026rdquo; mapping data.queryResult to $flow.queryResult\nAdd query activity by selecting GraphBuilder_TGDB -\u0026gt; TGDBQuery activity\nSelect \u0026ldquo;TGDB\u0026rdquo; connection which we just created in lab1 so the TGDBQuery activity is going to query against the server which we've updated/inserted the Northwind data to\nMap input data for TGDBQuery activity\n QueryType : $flow.queryType  Add return activity to link the query result back to HTTP trigger\nMap outputs for Return activity\n queryResult : $activity[TGDBQuery].queryResult (map entire object)  You've finished creating metadata query flow\nClick \u0026ldquo;Create\u0026rdquo; button to create another flow for querying the content of Northwind graph\nAdd name and description for the new flow\nDefine the flow inputs data schema by pasting sample data (schema detail see TGDB documentation)\n queryType : search (for content flow) language : TGQL (TIBCO graph query language) or Gremlin queryString : for TGQL and Gremlin traversalCondition : TGQL only traversalDepth : TGQL only  Click save to generate data schema definition\nFlow output data schema same as metadata flow.\nAdd another trigger for receiving content query\nPOST method for content query\nAdding sample query for the output (to the flow) setting. To be noticed that the schema is very similar to flow input schema but grouped under \u0026ldquo;query\u0026rdquo; keyword.\nMap to flow input\n queryType : $trigger.pathParams.queryType language : $trigger.body.query.language queryString : $trigger.body.query.queryString traversalCondition : $trigger.body.query.traversalCondition endCondition : $trigger.body.query.endCondition traversalDepth : $trigger.body.query.traversalDepth  Click save\nSet the reply data (same as metadata flow) Add query activity by select GraphBuilder_TGDB -\u0026gt; TGDBQuery activity\nSelect \u0026ldquo;TGDB\u0026rdquo; connection we just created in lab1 so the TGDBQuery activity is going to query against the server which we've inserted/updated Northwind data to\nMap input data for TGDBQuery activity\n QueryType : $flow.queryType params.language : $flow.language params.queryString : $flow.queryString params.traversalCondition : $flow.traversalCondition params.endCondition : $flow.endCondition params.traversalDepth : $flow.traversalDepth  Add \u0026ldquo;Return\u0026rdquo; activity to link the query result back to HTTP trigger\nMap outputs for Return activity\n queryResult : $activity[TGDBQuery].queryResult (map entire object)  The TGDB_RESTful_Service is configured and it's ready for query Nothwind graph\nNow it's time to test out TGDB_RESTful_Service and to \u0026ldquo;see\u0026rdquo; Nothwind data by query against TGDB server\nFor building flogo application\n In project click \u0026ldquo;Build\u0026rdquo; button Select the build target OS (in my case Darwin/amd64) then click to build  Once finished you can get your executable in your browser's download folder\nFind your executable and change its permission to executable then run it\nSwitch to your local labs -\u0026gt; utilities -\u0026gt; lite folder\n Launch UI tool by type \u0026ldquo;npm start\u0026rdquo; You need to have npm and lite-server installed before you use this tool  As soon as you launch the server, your default browser will pop up and show Project GraphBuilder UI utility For querying data against TGDB server clicks \u0026ldquo;TGDB Data\u0026rdquo; tab\nYou can make query to TGDB using TGQL expression as screenshot bellow\nYou now can see the Nothwind data from TGDB server in life\n","excerpt":"Create a new flogo application called \u0026ldquo;TGDB_RESTful_Service\u0026rdquo;\nClick \u0026ldquo;+ …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/labs/lab-2/","title":"Lab2 - Query"},{"body":" TGDB Connector : A TGDB connector is a component to store your TIBCO® Graph Database server connection information. Activities which connect to the same TGDB connector are actually connecting to the same TIBCO® Graph Database server instance TGDBUpsert : A TGDBUpsert activity consumes the graph entities from BuildGraph activity and inserts/updates them to TIBCO® Graph Database TGDBQuery : With TGDBQuery activity users can build their own application to query against TIBCO® Graph Database. It support both TGQL and Gremlin query language TGDBDelete : TGDBDelete activity implemeting the deletion of graph entities for TIBCO® Graph Database. It takes graph entities (with primary key attributes populated) from BuildGraph then performs the deletion on them  ","excerpt":"TGDB Connector : A TGDB connector is a component to store your TIBCO® Graph Database server …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-tgdb/","title":"TGDB"},{"body":" Connector : A Dgraph connector is a component to store your Dgraph server connection information. Activities which connect to the same Dgraph connector would connect to the same Dgraph server instance DgraphUpsert : A DgraphUpsert activity consumes the graph entities from BuildGraph activity and inserts/updates them to Dgraph server  ","excerpt":" Connector : A Dgraph connector is a component to store your Dgraph server connection information. …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-dgraph/","title":"Dgraph"},{"body":"Implementation Source Download application artifacts from here.\nDownload GraphBuilder user extensions from here\nInstallation Open TIBCO Flogo® Enterprise 2.8.1 studio and upload required user extensions (builder.zip, dgraph.zip and tools.zip)\nFollow the Airline example to continue importing application\n This example is created in TIBCO Flogo® Enterprise 2.8.1 studio.\n ","excerpt":"Implementation Source Download application artifacts from here.\nDownload GraphBuilder user …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/iot-data-consumer/","title":"IoT Data Consumer"},{"body":"Now let's create an application which receives real-time order events from Kafka topic then build graph entities (nodes, edges and their attributes), insert/update entities to TGDB then serve real-time graph entities as a streaming server.\nFirst of all create an internal \u0026ldquo;Server Sent Event (SSE)\u0026rdquo; connection to link between order event flow and SSE server flow (for serving streaming graph entities to external client).\nIn \u0026ldquo;Connections\u0026rdquo; tab select GraphBuilder_SSE -\u0026gt; Server-sent Events Connection\nConnection settings (following settings match the client tool which is provided for browsing real-time graph entity update)\n Connection Name : Set name to \u0026ldquo;EventServer\u0026rdquo; Outbound : Set false as it's a server Server port : 8888 Path : It's URI path \u0026ldquo;/sse/\u0026rdquo; TLS enabled : false  Click \u0026ldquo;Connect\u0026rdquo;\nBack to Northwind application to create a new flow called \u0026ldquo;Order Event Server\u0026rdquo;\nSelect a \u0026ldquo;SSE Server\u0026rdquo; trigger to serve graph entities (come from order event flow) for streaming client\nSettings\n Connection Name : Select the \u0026ldquo;EventServer\u0026rdquo; connection which we just created  Click \u0026ldquo;Save\u0026rdquo;\nThis simple flow will be serving streaming graph entities\nNow Add the last flow for Northwind application. It is \u0026ldquo;Order Data Flow\u0026rdquo; which listen to Kafla topic to consume order events as input data of the flow.\nBefore we create it, we need to create a \u0026ldquo;Kafka Connection\u0026rdquo;. In connection tab select \u0026ldquo;Appach Kafka Client Configuration\u0026rdquo;\nConfigure Appach Kafka Client as following screenshot then save it\nBack to application to create new flow called \u0026ldquo;Order Event\u0026rdquo;\nClick \u0026ldquo;Flow Inputs \u0026amp; Outputs\u0026rdquo; (vertical blue bar) to define schema between flow and trigger. Set following data sample then click save\nAfter clicking save button schema generator would convert sample data to schema definition like before\nClick \u0026ldquo;+\u0026rdquo; to add trigger (Kafka Consumer)\nSelect \u0026ldquo;Northwind Orders\u0026rdquo; configuration we just created then click continue.\nSelect \u0026ldquo;Just Add Trigger\u0026rdquo; button to add trigger\nFinish the trigger setting as it shown below in screenshot\nMap OrderString to $trigger.stringValue\nAdd CSVParser to convert incoming CVS string to system object\nFollow the instruction in lab1 define the mapping between CSV fields and attribute of system object. Use the column field name as attribute name.\nMake sure \u0026ldquo;First Row Is Header\u0026rdquo; set to false\nConfigure the input\n CSVString : $flow.OrderString Leave SequenceNumber not mapped  After the data has bean transform to the object which could be recognized by the system. The next step is to convert data to graph entities (nodes, edges and their attributes). We use the core activity \u0026ldquo;Build Graph\u0026rdquo; to perform this tranformation. Let's select GraphBuilder -\u0026gt; Bruild Graph and configue it.\nFollow lab1's instruction to turn on the \u0026ldquo;iterator\u0026rdquo; for iterating through upstream output data (at runtime) then map with input data of BuildGraph activity. Here is the mapping\nProduct node\n ProductID -\u0026gt; $iteration[value].ProductID  Employee node\n EmployeeID -\u0026gt; $iteration[value].EmployeeID  Customer node\n CustomerID -\u0026gt; $iteration[value].CustomerID  Order node\n OrderID -\u0026gt; $iteration[value].OrderID CustomerID -\u0026gt; $iteration[value].CustomerID EmployeeID- \u0026gt; $iteration[value].EmployeeID OrderDate -\u0026gt; $iteration[value].OrderDate RequiredDate -\u0026gt; $iteration[value].RequiredDate ShippedDate -\u0026gt; $iteration[value].ShippedDate ShipVia -\u0026gt; $iteration[value].ShipVia Freight -\u0026gt; $iteration[value].Freight ShipName -\u0026gt; $iteration[value].ShipName ShipAddress -\u0026gt; $iteration[value].ShipAddress ShipCity -\u0026gt; $iteration[value].ShipCity ShipRegion -\u0026gt; $iteration[value].ShipRegion ShipPostalCode - \u0026gt; $iteration[value].ShipPostalCode ShipCountry -\u0026gt; $iteration[value].ShipCountry  Suborder node\n OrderID -\u0026gt; $iteration[value].OrderID ProductID -\u0026gt; $iteration[value].ProductID UnitPrice -\u0026gt; $iteration[value].UnitPrice Quantity -\u0026gt; $iteration[value].Quantity Discount -\u0026gt; $iteration[value].Discount  Region node\n RegionName -\u0026gt; $iteration[value].RegionName Country -\u0026gt; $iteration[value].Country  Since one order can be splited to multiple order events (with different product sold). We create two types of order nodes 1. Odrer node (main order) with OrderID as its primary key and 2. Suborder node with OrderID, ProductID as primary key. BuildGraph activity would link (via edge) All Suborder nodes to Order node by matching their the OrderID. (See following screenshot)\nOrder :\nSuborder :\nFollow lab1's instruction to add TGDBUpsert activity\nSelect Connetion\nMap input data\nNow adding a new type of activity called SSEEndPoint which sends graph entities to SSEServer for serving streaming client.\nSelect SSEEndPoint activity from GraphBuilder_SSE.\nSelect \u0026ldquo;SSEConnection\u0026rdquo; we created and used in SSEServer earlier then the new SSEEndPoint is connected to SSEServer now.\nSetup SessionId to \u0026ldquo;order\u0026rdquo; so the complete URI to access to this event flow would be /sse/order\nMap input data to Graph object from BuildGraph activity\nWe can add log and GraphtoFile activities like previous configured flows.\nNow we have finish the last flow for our Northwind application.\nThis is the final version of flogo Northwind application\nLet's rebuild application for further testing\nWe are going to install Kafka message bus for providing order event. Here is the instalation instructions.\nAfter downloading and installing Kafka we can start Kafka\n Start zoo keeper   Start server   Create \u0026ldquo;test\u0026rdquo; topic  Let's restart Northwind appliction executable.\n Switch to the folder which contains Northwind appliction executable (Northwind-darwin_amd64). Change Northwind-darwin_amd64's permission to executable Run Northwind-darwin_amd64  This time you'll see two extra information while Northwind application starting\n Kafka consumer (the trigger of order event flow) is up and listening SSEServer is up and waiting for client (UI utility) to connect  Here it the our test (see screenshot)\n Make sure TGDB, TGDB_RESTful_Service, Kafka (server, zoo keeper, producer) and UI utility are running On the upper/middle left of screenshot open oerders.csv file On the lower left of screenshot start Kafka producer and keep it opened On the right follow the instruction to 1. Click \u0026ldquo;Realtime Data\u0026rdquo; 2. Click \u0026ldquo;Connect\u0026rdquo; to connect to SSE server in Northwind application 3. Copy \u0026amp; paste order to Kafka producer then press enter 4 ~ 6. Each time you send one order you will see the corresponding graph entities showing on the UI.  Send more order as your wish.\nAfter the streaming testing we also want to see the order in TGDB. Follow the instrctions in lab2\n Click \u0026ldquo;TGDB Data\u0026rdquo; button Use the default query setup but make traversalDepth = 5 Click \u0026ldquo;Make Query\u0026rdquo; button  You'll see the oder with OrderID = 10248 and its associated graph entities on the UI\nThe last test is about traversal query. We are going to find all companies which supply prodcuts within the order from the company \u0026lsquo;Vins et alcools Chevalier\u0026rsquo;. We are going to use Postman and TGDB_RESTful_Service to query against TGDB server\n Open a postman and setup a POST query The gremlin query is \u0026ldquo;g.V().has(\u0026lsquo;Company\u0026rsquo;, \u0026lsquo;CompanyID\u0026rsquo;, \u0026lsquo;Vins et alcools Chevalier\u0026rsquo;).in(\u0026lsquo;Customer_Company\u0026rsquo;).in(\u0026lsquo;SoldTo\u0026rsquo;).out(\u0026lsquo;Includes\u0026rsquo;).out(\u0026lsquo;Contains\u0026rsquo;).in(\u0026lsquo;Supplies\u0026rsquo;).out(\u0026lsquo;Supplier_Company\u0026rsquo;);\u0026rdquo;  You should get \u0026ldquo;Formaggi Fortini s.r.l.\u0026quot;, \u0026ldquo;Leka Trading\u0026rdquo; and \u0026ldquo;Cooperativa de Quesos \u0026lsquo;Las Cabras\u0026rsquo;\u0026rdquo; in your result\nObserve the traversal request on the UI utility and verify the correctness of the query\nCongradulations! Now you've finished all three labs\n","excerpt":"Now let's create an application which receives real-time order events from Kafka topic then build …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/labs/lab-3/","title":"Lab3 - real-time"},{"body":"We are going to use the Northwind dataset to create an Flogo application. The Northwind data is a sample dataset used by Microsoft to demonstrate the features of Microsoft's relational database. We will demonstrate how to use GraphBuilder to convert relational data to graph then insert into TIBCO® Graph Database.\nYou can check out or download Project GraphBuilder from here and the artifacts which you need for your labs project\n Download GraphBuilders user extensions here Download project data, graph model and TGDB configuration here Sownload GUI utilities here  In the labs we use TIBCO Flogo® Enterprise studio to configure the lab applications. You need to have it installed before you can start building the application. You can get TIBCO Flogo® Enterprise studio from here\nAfter installed studio import all required user extensions files (builder.zip, tgdb.zip, tools.zip and sse.zip)\n In \u0026ldquo;Extensions\u0026rdquo; tab click \u0026ldquo;Upload\u0026rdquo; button Click \u0026ldquo;From a Zip file\u0026rdquo; Each time select one user extension (for example builder.zip) from your download folder Click \u0026ldquo;Upload and compiling\u0026rdquo;  Click \u0026ldquo;Done\u0026rdquo; when extension get uploaded and compiled\nUploaded extension will be display on left panel\nKeep uploading all other required extensions. Here is all four required user extensions\n GraphBuilder GraphBuilder_TGDB GraphBuilder_Tools GraphBuilder_SSE  Now you are good to go for the upcoming labs\n","excerpt":"We are going to use the Northwind dataset to create an Flogo application. The Northwind data is a …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/labs/","title":"Labs"},{"body":" Graph Connector : A Graph connector is a component which hosts your graph model for sharing graph model among graph construction related activity. Activities which connect to the same Graph connector would share same graph model (data schema) BuildGraph Activity : A BuildGraph activity must connect to a Graph connector so it can build its input data schema from the graph model which is hosted in that Graph connector. BuildGraph activity transform the input data to graph entities (nodes, edges and their attributes) based on the graph model. TGDB Connector : A TGDB connector is a component to store your TIBCO® Graph Database server connection information. Activities which connect to the same TGDB connector are actually connecting to the same TIBCO® Graph Database server instance TGDBUpsert : A TGDBUpsert activity consumes the graph entities from BuildGraph activity and inserts/updates them to TIBCO® Graph Database  ","excerpt":"Graph Connector : A Graph connector is a component which hosts your graph model for sharing graph …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/","title":"Components"},{"body":"This example uses Meetup open event through Meetup API see https://www.meetup.com/meetup_api/\nCreate Graph Model Setting  Graph Name: -\u0026gt; Meetup Model Source: -\u0026gt; Select Local File Graph Model: -\u0026gt; Select sample-applications/Meetup_Event/Model_Meetup.json  Create Connection for subscribing Meetup open event Setting  Connection Name: -\u0026gt; Meetup_Event Outbound: -\u0026gt; Sellect \u0026ldquo;true\u0026rdquo; for connecting to Meetup service Server URL: -\u0026gt; http://stream.meetup.com/ Resource Name: -\u0026gt; 2/open_events Access Token: -\u0026gt; not required for accessing open event  Create Connection for serving streaming graph data Setting  Connection Name: -\u0026gt; EventServer Outbound: -\u0026gt; select \u0026ldquo;false\u0026rdquo; since it's a server Server port: -\u0026gt; any available port (8888 for this example) Path: -\u0026gt; /sse/ (client connect http://[host]:[port]/sse/meetup to subscribe \u0026ldquo;meetup\u0026rdquo; graph stream)  Create GraphModel for Enriching Meetup Graph Setting  Graph Name: -\u0026gt; GeographyInfo Model Source: -\u0026gt; Select Local File Graph Model: -\u0026gt; Select sample-applications/Meetup_Event/Model_GeographyInfo.json  Create Application Create Flow for consuming Meetup open event Configure flow inputs and outputs  input sample  {\r\u0026quot;EventString\u0026quot; : \u0026quot;\u0026quot;\r}\rAdd Activity 1 Select GraphBuilder_Tools -\u0026gt; JSONDeserializer\n JSON Data Sample: -\u0026gt; Select sample-applications/Meetup_Event/.json Default Values: -\u0026gt; Set \u0026ldquo;na\u0026rdquo; as default for venue.address_1, category.name  Add Activity 2 Select GraphBuilder_Builder -\u0026gt; BuildGraph\n Graph Model: -\u0026gt; Select \u0026ldquo;Meetup\u0026rdquo; (the connection we created previously) Configure Model: -\u0026gt; Map attributes to input data fields (for nodes and edges)  Add Activity 3-1 Select GraphBuilder_SSE -\u0026gt; SSEEndPoint\n SSE Connection: -\u0026gt; Select \u0026ldquo;EventServer\u0026rdquo; for serving streaming data(the connection we created previously) Avtivity Input 1: set StreamId to \u0026ldquo;meetup\u0026rdquo; (the resource name for client to subscribe) Avtivity Input 2: map required Data object to $activity[BuildGraph].Graph (output of BuildGraph activity)  Add Activity 3-2 Select GraphBuilder_TGDB -\u0026gt; TGDBUpsert\n TGDB Connection: -\u0026gt; Select \u0026ldquo;TGDB\u0026rdquo; for upserting streaming data to TGDB(the connection we created in TGDB_RESTful_Service sample application) Avtivity Input 1: set required Graph object to $activity[BuildGraph].Graph  Add a trigger Select GraphBuilder_SSE -\u0026gt; SSESubscriber\n SSE Connection(outbound request): -\u0026gt; Select \u0026ldquo;Meetup_Event\u0026rdquo; for consuming open event from Meetup web site Flow Input: -\u0026gt; Map EventString to $trigger.Event (This is the output of SSESubscriber)  Create Flow for Serving Streaming Graph Data Configure flow inputs and outputs No configuration is required here since the data flow comes from SSEEndPoint of Meetup Event Flow directly\nAdd a trigger GraphBuilder_SSE -\u0026gt; SSESubscriber\n  SSE Connection(inbound requests): -\u0026gt; Select \u0026ldquo;EventServer\u0026rdquo; for serving streaming data(so now SSEEndPoint connected)\n  Flow Input: -\u0026gt; Map EventString to $trigger.Event (This is the output of SSESubscriber)\n  Incoming Query\n  HTTP GET with resource path /sse/{streamId}\n reply  $flow.queryResult\nsample :\n{\r\u0026quot;graph\u0026quot;:{\r\u0026quot;edges\u0026quot;:{},\r\u0026quot;id\u0026quot;:\u0026quot;GeographyInfo\u0026quot;,\r\u0026quot;model\u0026quot;:{\r\u0026quot;edges\u0026quot;:{\r\u0026quot;attrTypeMap\u0026quot;:{\u0026quot;in_Continent\u0026quot;:{}},\r\u0026quot;directionMap\u0026quot;:{\u0026quot;in_Continent\u0026quot;:1},\r\u0026quot;keyMap\u0026quot;:{\u0026quot;in_Continent\u0026quot;:null},\r\u0026quot;types\u0026quot;:[\u0026quot;in_Continent\u0026quot;],\r\u0026quot;vertexes\u0026quot;:{\u0026quot;in_Continent\u0026quot;:[\u0026quot;City\u0026quot;,\u0026quot;Continent\u0026quot;]}\r},\r\u0026quot;nodes\u0026quot;:{\r\u0026quot;attrTypeMap\u0026quot;:{\u0026quot;Continent\u0026quot;:{\u0026quot;Name\u0026quot;:\u0026quot;String\u0026quot;},\u0026quot;Country\u0026quot;:{\u0026quot;Country_Code\u0026quot;:\u0026quot;String\u0026quot;}},\r\u0026quot;keyMap\u0026quot;:{\u0026quot;Continent\u0026quot;:[\u0026quot;Name\u0026quot;],\u0026quot;Country\u0026quot;:[\u0026quot;Country_Code\u0026quot;]},\u0026quot;types\u0026quot;:[\u0026quot;Country\u0026quot;,\u0026quot;Continent\u0026quot;]\r}\r},\r\u0026quot;modelId\u0026quot;:\u0026quot;GeographyInfo\u0026quot;,\r\u0026quot;nodes\u0026quot;:{\r\u0026quot;Continent_0ecff3229a1a13980689def44b2c66e1\u0026quot;:{\r\u0026quot;attributes\u0026quot;:{\u0026quot;Name\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;Name\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;String\u0026quot;,\u0026quot;value\u0026quot;:\u0026quot;North_America\u0026quot;}},\r\u0026quot;key\u0026quot;:[\u0026quot;North_America\u0026quot;],\r\u0026quot;keyAttributeName\u0026quot;:[\u0026quot;Name\u0026quot;],\r\u0026quot;type\u0026quot;:\u0026quot;Continent\u0026quot;\r},\r\u0026quot;Country_5181a8acdef7be40dfbf3ec66bee2b20\u0026quot;:{\r\u0026quot;attributes\u0026quot;:{\u0026quot;Country_Code\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;Country_Code\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;String\u0026quot;,\u0026quot;value\u0026quot;:\u0026quot;us\u0026quot;}},\r\u0026quot;key\u0026quot;:[\u0026quot;us\u0026quot;],\r\u0026quot;keyAttributeName\u0026quot;:[\u0026quot;Country_Code\u0026quot;],\r\u0026quot;type\u0026quot;:\u0026quot;Country\u0026quot;\r}\r}\r}\r}\rCreate Flow for Enriching Meetup Graph Configure flow inputs and outputs  input sample  {\r\u0026quot;Continent\u0026quot;: {\r\u0026quot;Name\u0026quot;: \u0026quot;North_America\u0026quot;,\r\u0026quot;Countries\u0026quot;: [\r\u0026quot;us\u0026quot;\r]\r}\r}\rAdd Activity 1 Select GraphBuilder_Builder -\u0026gt; BuildGraph\n Graph Model: -\u0026gt; Select \u0026ldquo;GeographyInfo\u0026rdquo; (the connection we created previously) Configure Model: -\u0026gt; Map attributes to input data fields (for nodes and edges)  Add Activity 2 Select GraphBuilder_SSE -\u0026gt; SSEEndPoint\n SSE Connection: -\u0026gt; Select \u0026ldquo;EventServer\u0026rdquo; for serving streaming data(the connection we created previously) Avtivity Input 1: set StreamId to \u0026ldquo;GeographyInfo\u0026rdquo; (the resource name for client to subscribe) Avtivity Input 2: map required Data object to $activity[BuildGraph].Graph (output of BuildGraph activity)  Add a trigger (Receive HTTP Message)   Setting1: Set Port to any available one (in this sample 9998)\n  Setting2: Set Method to \u0026ldquo;POST\u0026rdquo;\n  Setting3: Set Path to \u0026ldquo;/geography/{Continent}\u0026rdquo;\n  Output Setting\n  $trigger.pathParams.Continent and $trigger.body\nbody sample :\n{\r\u0026quot;Countries\u0026quot;: [\r\u0026quot;us\u0026quot;\r]\r}\r Flow Input1: Continent.Name map to $trigger.pathParams.Continent Flow Input2: Continent.Countries map to $trigger.body.Countries  Implementation Source stored on GitHub here.\n This example is created in TIBCO Flogo® Enterprise 2.8.0 studio.\n ","excerpt":"This example uses Meetup open event through Meetup API see https://www.meetup.com/meetup_api/\nCreate …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/meetup-event/","title":"Meetup Event"},{"body":" Connector : A Neo4j connector is the component to store your Neo4j server connection information. Activities which connect to the same Neo4j connector would connect to the same Neo4j server instance Neo4jUpsert : A Neo4jUpsert activity consumes the graph entities from BuildGraph activity and inserts/updates them to Neo4j server  ","excerpt":" Connector : A Neo4j connector is the component to store your Neo4j server connection information. …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-neo4j/","title":"Neo4j"},{"body":"Project Graph Builder offers an easy and powerful way of loading data from multiple enterprise data sources into TIBCO® Graph Database in real time to leverage the power of all the business insights that are captured in your data.\nPutting the relationships within your data at the forefront allows you to traverse and understand complex relationships within your business model. Storing data in a graph model allows you to convert complex dynamic data into meaningful business insights.\n","excerpt":"Project Graph Builder offers an easy and powerful way of loading data from multiple enterprise data …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/","title":"Sample Applications"},{"body":"  Connector : A gremlin connector is the component to store your Janusgraph server connection information. Activities which connect to the same gremlin connector would connect to the same Janusgraph server instance\n  JanusgraphUpsert : A JanusgraphUpsert activity consumes the graph entities from BuildGraph activity and inserts/updates them to Janusgraph server\n  ","excerpt":"  Connector : A gremlin connector is the component to store your Janusgraph server connection …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-gremlin/","title":"Gremlin"},{"body":"Create TGDB Connection Create Application Create Flow for querying Metadata Configure flow inputs and outputs  input sample  {\r\u0026quot;queryType\u0026quot; : \u0026quot;\u0026quot;\r}\r output sample  {\r\u0026quot;queryResult\u0026quot;: {\r\u0026quot;content\u0026quot;: {},\r\u0026quot;success\u0026quot;: true,\r\u0026quot;error\u0026quot;: {\r\u0026quot;code\u0026quot;: 101,\r\u0026quot;message\u0026quot;: \u0026quot;Not found\u0026quot;\r}\r}\r}\rAdd activities   Activity 1 : GraphBuilder_TGDB -\u0026gt; TGDBQuery\n  Activity 2 : Default -\u0026gt; Return\n  Add a trigger (Receive HTTP Message)  output  $trigger.pathParams.queryType\n reply  $flow.queryResult\nsample :\n{\r\u0026quot;queryResult\u0026quot;: {\r\u0026quot;content\u0026quot;: {},\r\u0026quot;success\u0026quot;: true,\r\u0026quot;error\u0026quot;: {\r\u0026quot;code\u0026quot;: 101,\r\u0026quot;message\u0026quot;: \u0026quot;Not found\u0026quot;\r}\r}\r}\rCreate Flow for Querying Data Configure flow inputs and outputs  input sample  {\r\u0026quot;queryType\u0026quot; : \u0026quot;\u0026quot;,\r\u0026quot;language\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;queryString\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;traversalCondition\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;endCondition\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;traversalDepth\u0026quot;: 1\r}\r output sample  {\r\u0026quot;queryResult\u0026quot;: {\r\u0026quot;content\u0026quot;: {},\r\u0026quot;success\u0026quot;: true,\r\u0026quot;error\u0026quot;: {\r\u0026quot;code\u0026quot;: 101,\r\u0026quot;message\u0026quot;: \u0026quot;Not found\u0026quot;\r}\r}\r}\rAdd activities   Activity 1 : GraphBuilder_TGDB -\u0026gt; TGDBQuery\n  Activity 2 : Default -\u0026gt; Return\n  Add a trigger (Receive HTTP Message)  output  $trigger.pathParams.queryType and $trigger.body\nsample :\n{\r\u0026quot;query\u0026quot;: {\r\u0026quot;language\u0026quot; : \u0026quot;tgql\u0026quot;,\r\u0026quot;queryString\u0026quot; : \u0026quot;@nodetype = 'houseMemberType' and memberName = 'Napoleon Bonaparte';\u0026quot;,\r\u0026quot;traversalCondition\u0026quot; : \u0026quot;@edgetype = 'relation' and relation = 'spouse' and @isfromedge = 1 and @degree = 1;\u0026quot;,\r\u0026quot;endCondition\u0026quot; : \u0026quot;\u0026quot;,\r\u0026quot;traversalDepth\u0026quot; : 1\r}\r}\r reply  $flow.queryResult\nsample :\n{\r\u0026quot;queryResult\u0026quot;: {\r\u0026quot;content\u0026quot;: {},\r\u0026quot;success\u0026quot;: true,\r\u0026quot;error\u0026quot;: {\r\u0026quot;code\u0026quot;: 101,\r\u0026quot;message\u0026quot;: \u0026quot;Not found\u0026quot;\r}\r}\r}\rImplementation Source stored on GitHub here.\n This example is created in TIBCO Flogo® Enterprise 2.8.0 studio.\n ","excerpt":"Create TGDB Connection Create Application Create Flow for querying Metadata Configure flow inputs …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/restful-service/","title":"RESTful Service"},{"body":"  Connector : A SSE connector is a component to store your sse server (Outbound = false) configuration or remote sse server connection (Outbound = true) information. Activities connect to same the SSE connector are connecting to the same SSE service.\n  SSESubscriber : A \u0026ldquo;SSESubscriber trigger\u0026rdquo; subscribes to remote sse server then consumes streaming events. The SSE Connector for a subscriber need to be configured as Outbound = true.\n  SSEServer : A \u0026ldquo;SSEServer trigger\u0026rdquo; works as an SSE server which serves streamming events. It maitains the incoming connection and requests but won't generate any data itself. The streaming data comes from another activity called SSEEndPoint. The SSE Connector for a subscriber need to be configured as Outbound = false\n  SSEEndpoint : A SSEEndpoint activity sits on different flow (a data flow) from SSEServer. It takes input event and streams it to SSEServer. The link between a SSEServer and a SSEEndPoint is that both of them need to connect to the same SSE connector (Outbound = false)\n  ","excerpt":"Connector : A SSE connector is a component to store your sse server (Outbound = false) configuration …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-sse/","title":"SSE"},{"body":" FileReader : Read data from single file, files in a folder or file entries in a zip file Accumulator : Accumulate input data then emits it in a batch CSVFileWriter : Write data to file in CSV format CSVParser : Parse data from CSV file based on predefined path then set to a flate tuple JsonDataDecoupler : Extract array data from JSON then emits a array of tuples JsonDeserializer : Convert JSON string to an object JsonParser : Parse data from JSON file based on predefined path then set to a flate tuple JsonSerializer : Convert an object to JSON string  ","excerpt":" FileReader : Read data from single file, files in a folder or file entries in a zip file …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-tools/","title":"Tools"},{"body":"This section is where the user documentation for TIBCO LABS™ Project GraphBuilder - all the information you need to understand this project.\n","excerpt":"This section is where the user documentation for TIBCO LABS™ Project GraphBuilder - all the …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/","title":"Documentation"},{"body":"","excerpt":"","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/index.json","title":""},{"body":"\r\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/about/featured-background_hud062541b21b90529446eee6001de80cd_8365555_960x540_fill_q75_catmullrom_bottom.jpg); }\r@media only screen and (min-width: 1200px) {\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/about/featured-background_hud062541b21b90529446eee6001de80cd_8365555_1920x1080_fill_q75_catmullrom_bottom.jpg); }\r}\r\rProject Graph Builder by TIBCO LABS™\rProject GraphBuilder offers an easy and powerful way to load data from multiple enterprise data sources into TIBCO GraphDB or any graph database of your choice, both in batch and real-time. Leverage the power of relationships to discover new business insights that were previously hidden in your data. Project GraphBuilder makes it simple for you to efficiently traverse, analyze, and access complex relationships across your organization, and convert this dynamic data into a form that is easy to understand and leverage. abc line 2\r--\r\r\r\r\r\r\r\rMore Details about the underlying Product here TIBCO® Graph Database Wiki, on \r\r\r\r\rTIBCO LABS™ is a program designed to provide customers and partners with a mechanism for actively participating in TIBCO’s history of innovation.\rTIBCO has always been at the forefront of innovation, and TIBCO LABS™ allows participants to share in this history by collaboratively building solutions to today’s challenging problems, previewing new capabilities, and accessing emerging technologies in areas such as blockchain, AI / ML and IoT. Through TIBCO LABS™, customers and partners can gain insight into TIBCO’s innovation activities, participate in shaping the form of these activities in the years to come, and benefit from TIBCO’s leadership position in integration and analytics.\r\n\r\r\r\r\n\r\r\r\r\rBSD 3-Clause License \rCopyright © 2020 TIBCO Software Inc. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n  Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n  Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n  Neither the name of TIBCO Software Inc. nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT OWNER AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\r\r\r\r","excerpt":"#td-cover-block-0 {\rbackground-image: …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/about/","title":"About Project Graph Builder"},{"body":"","excerpt":"","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/community/","title":"Community"},{"body":"\r\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/featured-background_hud062541b21b90529446eee6001de80cd_8365555_960x540_fill_q75_catmullrom_top.jpg); }\r@media only screen and (min-width: 1200px) {\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/featured-background_hud062541b21b90529446eee6001de80cd_8365555_1920x1080_fill_q75_catmullrom_top.jpg); }\r}\r\rProject GraphBuilder\rLearn More \r\rDownload \r\rLeveraging the power of relationships in your data\n\n\r\r\r\r\r\r\r\rProject GraphBuilder by TIBCO LABS™\nThe application of graph analytics keeps growing in the market and it is becoming more relevant in today's world. The need to continuously accelerate the data ingestion into graph models to enable fast analysis of complex interrelationships in the data sometimes can be hard to meet. Project Graph Builder by TIBCO LABS™ addresses these challenges by providing an easy and powerful way to load data into TIBCO® Graph Database.\n\r\r\r\r\r\rOverview\rBusiness use case, followed by the Proposed of the Solution.\nRead more …\n\r\r\rComponents\rLearn more about the used TIBCO Products and Assets.\nRead more …\n\r\r\rGet Started\rFollow the documentation, and start today !\nRead more …\n\r\r\r--\r\r\r\r\r\r\rContact us!\rReach us for more details, or engage us today !\nRead more …\n\r\r\rContributions welcome!\rWe do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n\r--\r\r\rFollow us on Twitter!\rFor announcement of latest features etc\u0026hellip;\nRead more …\n\r\r\r\r","excerpt":"#td-cover-block-0 {\rbackground-image: …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/","title":"Project Graph Builder"},{"body":"","excerpt":"","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/search/","title":"Search Results"}]