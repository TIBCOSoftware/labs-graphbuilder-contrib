[{"body":"Details coming soon here!\nImplementation Source stored on GitHub here.\n This example is created in TIBCO Flogo® Enterprise 2.8.0 studio.\n ","excerpt":"Details coming soon here!\nImplementation Source stored on GitHub here.\n This example is created in …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/airline/","title":"Airline"},{"body":"Implementation Sources\n Connector BuildGraph GraphToFile  ","excerpt":"Implementation Sources\n Connector BuildGraph GraphToFile  ","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder/","title":"GraphBuilder"},{"body":"Let's build a graph model for Northwind data. In connection tab select Graph to host graph model for your flogo application. In the diaog box\n Set model name Select \u0026ldquo;Local File\u0026rdquo; select and upload northwind_model.json from your download folder Click connect  The Northwind model descriptor file has attached to your graph model Now let's select Application table then create to start building an allication Name the application \u0026ldquo;Northwind\u0026rdquo; then create it Select create to make it from scratch Flogo studio brings you to the dialog for creating the first flow. According to Northwind data set we have, we are going to create five flows to process data from customers.csv, suppliers.csv, employees.csv, categories.csv and products.csv respectively. We start from Building the customer data flow. In the empty flow panel click \u0026ldquo;Flow Inputs \u0026amp; Outputs\u0026rdquo; verticle bar to generate data schema for current flow. The flow processes a CSV data row from file each time. Just set a sample of incoming data. In the sample \u0026ldquo;FileContent\u0026rdquo; is a row of CSV data and \u0026ldquo;LineNumber\u0026rdquo; is current \u0026ldquo;row number\u0026rdquo; of the row. After clik \u0026ldquo;Save\u0026rdquo; buttom schema generator converts data sample to schema definition. Let's add a trigger (data source) for the flow by clicking \u0026ldquo;+\u0026rdquo; buttom on the left and select GraphBuilder_Tools -\u0026gt; FileReader trigger. Filling the \u0026ldquo;Trigger Settings\u0026rdquo;\n Filename : point to customers.csv in your download folder Asychroous : make it true so all triggers for different data would run simutanously Emit per Line : set true to make sure each time only one row of data sending to flow Max Number of Line : set to negative means no limit.  Click save after you finish it Now switch to \u0026ldquo;Map to Flow Inputs\u0026rdquo; and make following mapping\n FileContent (defined in schema) -\u0026gt; $trigger.FileContent LineNumber (defined in schema) -\u0026gt; $trigger.LineNumber  Then click save button Back to flow and adding first activities. Select GraphBuilder_Tools -\u0026gt; CSVParser for converting CSV text to system object. Filling Settings\n Date Format Sample : 2006-01-02 (GOLang data format) Serve Graph Data : set false since we are not using it Output Field Names : One line of setting for each data column. AttributeName is the field name in system object and CSVFieldName is the column name in CSV file. Set optional to \u0026ldquo;false\u0026rdquo; for all key element fields. Click save after set configuring each line. First Row is Heade : Set true since the data file we use has header  Click save button Switch to Inputs and map current input data to upstream output data\n CSVString -\u0026gt; $flow.FileContent SequenceNumber -\u0026gt; $flow.LineNumber  Click save when finish it Now the data has bean transform to the object which could be recognized by the system. The next step is to convert data to graph entities (nodes, edges and attributes). We use the core activity \u0026ldquo;Build Graph\u0026rdquo; to perform this tranformation. Let's select GraphBuilder -\u0026gt; Bruild Graph and configue it.\nFilling setting\n Graph Model : Select \u0026ldquo;Northwind\u0026rdquo; which we just created. The Northwind graph model now associated with this activity. You would see this when we setup Inputs. Allow Null Key : Will Generate node, edge even their primary key will null element. Batch Mode : Set false since we process one data each time. Pass Through Fields : (leave it empty) Modify Size of Instances : (leave it empty, will use it in Employee data setup)  Click save button Before we can map the input data let's take look of the output of CSVParser (upstream data of current Build Graph activity). Since CSVParser has ability to handle multiple CSV rows, the output of it is an array not just a single object. For procees the incoming array type of data, we need to turn on the iterator to iterate through upstream output data. Even there is only one element in the array for the current case. Following screenshot showing how to do it. For mapping the input data you may notice that 1. the Northwind graph model has been brought to this activity as input schema, 2. The mapping target is not to CSVParser but the local interation. For the data coming from customers.csv you can populate more than one type of nodes which are deinfed in Northwind graph. Here is the nodes data which will be set.\nCustomer node\n _skipCondition -\u0026gt; null==$iteration[value].CustomerID CustomerID -\u0026gt; $iteration[value].CustomerID CustomerName -\u0026gt; $iteration[value].CustomerName ContactName -\u0026gt; $iteration[value].ContactName ContactTitle -\u0026gt; $iteration[value].ContactTitle City -\u0026gt; $iteration[value].City RegionName -\u0026gt; $iteration[value].RegionName RegionCode -\u0026gt; $iteration[value].RegionCode Country -\u0026gt; $iteration[value].Country Phone -\u0026gt; $iteration[value].Phone Fax -\u0026gt; $iteration[value].Fax  Company node\n _skipCondition -\u0026gt; null==$iteration[value].CompanyID CompanyID -\u0026gt; $iteration[value].CompanyID CompanyName -\u0026gt; $iteration[value].CompanyName  Region node\n RegionName -\u0026gt; $iteration[value].RegionName Country -\u0026gt; $iteration[value].Country  You don't have to setup mapping for edge if you don't have attribute need to be setup for them (we don't configue \u0026ldquo;label\u0026rdquo; since TGDB doesn't need it). BuildGraph activity is going to use the edge definded in graph model to create edge between nodes automatically.\nAfter we convert data to graph entities we can insert them to TGDB. Let's create TGDB connection first. In Connections tab select Add Connection -\u0026gt; TGDB Connector In the diaog box filling following information\n Connection name (for example \u0026ldquo;TGDB\u0026rdquo;) TGDB Server URL Username Password Keep Connection Alive : select \u0026ldquo;true\u0026rdquo;  Click connect\nNow back to application \u0026ldquo;Customer Data\u0026rdquo; flow to add TGDB activity. Slect GraphBuilder_TGDB -\u0026gt; TGDBUpsert. Filling Setting for\n TGDB connection : Select the \u0026ldquo;TGDB\u0026rdquo; Connection we just created Set Allow empty sting key to true (so node with empty string key still get inserted)  Click save\nMap input data\n Graph{} - $activity[BuildGraph].Graph{}  Since the Graph object is immutable, you are not allow to access the internal structure detail.\nYou can insert built in log activity by following steps: Make room for logger activity by shifting activities one position to the right.\nAdd log activity by select Default -\u0026gt; Log\nSetup message for priniting (you can apply built-in fuctions to incoming data fields)\n message : string.concat(string.tostring($flow.LineNumber), \u0026quot; - \u0026ldquo;, $flow.FileContent)  You can add write the entities which generate be BuildGraph activity by adding GraphBuilder -\u0026gt; GraphtoFile activity\nSpecify the output folder and filename for writing the graph entities\nInput data is and only can be Graph. The input setup same as TGDBUpsert\nCongradulations you have finish the first data flow for the application\nNow you can follow the same steps to finish all the rest of flows\nWhen you work on employee flow, please pay attention on following steps.\nIn employee data there are two fields EmployeeID and ReportTo which represent one indivisual employee. It implies that by the infomation in the employee data we can populate two employee nodes. One for empoyee himself/herself and one for his/her manager. We have to incresae the employee instance for the data mapping.\n Modify size of instances : Select \u0026ldquo;Employee\u0026rdquo; node and make the number of instances to 2  Click save\nSwitch to Inputs you will see two employee nodes appears (Employee0 and Employee1). Let's make employee0 the employee (not manager) so all data can be populate to this node.\nWe make the emplyee1 node represent the manager of employee0 node so the only information we have for it (in the data) is \u0026ldquo;ReportTo\u0026rdquo; which will populate employee1's EmployeeID.\nThen we need to tell BuildGrap activity the relation between employee0 and employee1.\n","excerpt":"Let's build a graph model for Northwind data. In connection tab select Graph to host graph model for …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/labs/lab-1/","title":"Lab1 - CSV"},{"body":"By using GraphBuilder you are able to build your own application to\n Transform your data to desirded graph structure based upon your graph model. Insert graph into many major graph databases in the marcket (include TIBCO Graph Database, Dgraph, Neo4j and Janusgraph). Query and delete graph data against TIBCO Graph Database  ","excerpt":"By using GraphBuilder you are able to build your own application to\n Transform your data to desirded …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/overview/","title":"Overview"},{"body":" Download latest TIBCO Flogo Enterprise from here here Download GraphBuilder user extensions here import GraphBuilder user extensions to TIBCO Flogo Enterprise studio. Enjoy it!  ","excerpt":" Download latest TIBCO Flogo Enterprise from here here Download GraphBuilder user extensions here …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/getting-started/","title":"Getting Started"},{"body":"Details coming soon here!\nImplementation Source stored on GitHub here.\n This example is created in TIBCO Flogo® Enterprise 2.8.0 studio.\n ","excerpt":"Details coming soon here!\nImplementation Source stored on GitHub here.\n This example is created in …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/hierachy/","title":"Hierachy"},{"body":"Create a new flogo application called \u0026ldquo;TGDB_RESTful_Service\u0026rdquo;\nClick create to build from scratch\nCreate first flow to query metadata\nDefine the data schema for flow input by pasting sample data (queryType in string data type).\n queryType : metadata, edgetypes or nodetypes (for metadata flow)  Save sample data so schema builder can generate schema definition from it\nDefine flow output schema by sample output data\n Content : contains the data of query result Success : true means query go through without error Code : error code Message : error message  Click save\nSave trigger schema definition generation\nAdding trigger to receive HTTP request by clicking \u0026ldquo;+\u0026rdquo; -\u0026gt; \u0026ldquo;ReceiveHTTPMessage\u0026rdquo;\nSelect GET, setup resource path \u0026ldquo;/tgdb/{queryType}\u0026rdquo; then click continue\nClick \u0026ldquo;Just add the trigger\u0026rdquo; button\nWe have a trigger with HTTP GET methods and listen on port 9999)\nClick trigger to map incoming query data to flow input data\nIn \u0026ldquo;reply Settings\u0026rdquo; set reply schema make it same as flow output data schema\nIn \u0026ldquo;Map from flow outputs\u0026rdquo; mapping data.queryResult to $flow.queryResult\nAdd query activity by select GraphBuilder_TGDB -\u0026gt; TGDBQuery activity\nSelect \u0026ldquo;TGDB\u0026rdquo; coinnection we created in lab1 so the TGDBQuery activity is going to query against the server which we've upserted Northwind data to\nMap input data for TGDBQuery activity\n QueryType : $flow.queryType  Adding return activity to link the query result back to HTTP trigger\nMap outputs for Return activity\n queryResult : $activity[TGDBQuery].queryResult (map entire object)  You've finished creating metadata query flow\nClick \u0026ldquo;Create\u0026rdquo; button to create another flow for querying data content\nCreate name and description for the new flow\nDefine the flow inputs data schema by sample data (schema detail see TGDB documentation)\n queryType : search (for content flow) language : TGQL (TIBCO graph query language) or Gremlin queryString : for TGQL and Gremlin traversalCondition : TGQL only traversalDepth : TGQL only  Click save to generate data schema definition\nFlow output data schema same as metadata flow.\nAdd another trigger for receiving content query\nPOST method for content query\nAdding sample query for the output (to the flow) setting. To be noticed that the schema is very similar to flow input schema but grouped under \u0026ldquo;query\u0026rdquo; keyword.\nMap to flow input\n queryType : $trigger.pathParams.queryType language : $trigger.body.query.language queryString : $trigger.body.query.queryString traversalCondition : $trigger.body.query.traversalCondition endCondition : $trigger.body.query.endCondition traversalDepth : $trigger.body.query.traversalDepth  Click save\nSetting the reply data (same as metadata flow) Add query activity by select GraphBuilder_TGDB -\u0026gt; TGDBQuery activity\nSelect \u0026ldquo;TGDB\u0026rdquo; coinnection we created in lab1 so the TGDBQuery activity is going to query against the server which we've upserted Northwind data to\nMap input data for TGDBQuery activity\n QueryType : $flow.queryType params.language : $flow.language params.queryString : $flow.queryString params.traversalCondition : $flow.traversalCondition params.endCondition : $flow.endCondition params.traversalDepth : $flow.traversalDepth  Adding return activity to link the query result back to HTTP trigger\nMap outputs for Return activity\n queryResult : $activity[TGDBQuery].queryResult (map entire object)  The TGDB_RESTful_Service is ready for query Nothwind graph\n","excerpt":"Create a new flogo application called \u0026ldquo;TGDB_RESTful_Service\u0026rdquo;\nClick create to build from …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/labs/lab-2/","title":"Lab2 - Query"},{"body":"Implementation Sources\n Connector TGDBUpsert TGDBQuery TGDBDelete  ","excerpt":"Implementation Sources\n Connector TGDBUpsert TGDBQuery TGDBDelete  ","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-tgdb/","title":"TGDB"},{"body":"Implementation Sources\n Connector DgraphUpsert DgraphQuery  ","excerpt":"Implementation Sources\n Connector DgraphUpsert DgraphQuery  ","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-dgraph/","title":"Dgraph"},{"body":"Details coming soon here!\nImplementation Source stored on GitHub here.\n This example is created in TIBCO Flogo® Enterprise 2.8.0 studio.\n ","excerpt":"Details coming soon here!\nImplementation Source stored on GitHub here.\n This example is created in …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/iot-data-consumer/","title":"IoT Data Consumer"},{"body":"Now let's create an application which and receive real-time order events from Kafka topic then build graph entities, upsert to TGDB then serve as real-time streaming server.\nFirst of all create a \u0026ldquo;Server Sent Event\u0026rdquo; internal connection to bridge the data between order event flow and server (for serving streaming graph entity to client).\nIn \u0026ldquo;Connections\u0026rdquo; tab select GraphBuilder_SSE -\u0026gt; Server-sent Events Connection\nConnection settings (following settings match the client tool provided for browsing real-time graph entity update)\n Connection Name : Set name to \u0026ldquo;EventServer\u0026rdquo; Outbound : Set false as it's a server Server port : 8888 Path : It's URI path \u0026ldquo;/sse/\u0026rdquo; TLS enabled : false  Click connect\nBack to Northwind application to create a new flow called \u0026ldquo;Order Event Server\u0026rdquo;\nCreate a trigger to serve graph entities (generated by order event) for streaming client\nSettings\n Connection Name : Select the \u0026ldquo;EventServer\u0026rdquo; connection which we just created  Click save\nThis simple flow will be serving streaming graph entities\nThe last flow in Northwind application is \u0026ldquo;Order Data Flow\u0026rdquo; which listen to Kafla topic to get order event as input data.\nBefore we create the flow, we need to create a \u0026ldquo;Kafka Connection\u0026rdquo;. In connection tab select \u0026ldquo;Appach Kafka Client Configuration\u0026rdquo;\nConfigure Appach Kafka Client as following screenshot then save it\nBack to application to create new flow called \u0026ldquo;Order Event\u0026rdquo;\nClick Flow Inputs \u0026amp; Outputs (vertical blue bar) to define schema between flow and trigger. Set following data sample then click save\nAfter click save button schema generator would convert sample data to schema definition\nClick \u0026ldquo;+\u0026rdquo; to add trigger (Kafka Vonsumer)\nSelect \u0026ldquo;Northwind Orders\u0026rdquo; configuration we just created then click continue.\nSelect \u0026ldquo;Just Add Trigger\u0026rdquo; button to add trigger\nFilling trigger setting as it shown below in screenshot\nMap OrderString to $trigger.stringValue\nAdd CSVParser to convert incoming CVS string to system object\nFollow the instruction in lab1 define the mapping between CSV fields and attribute of system object. Use the column field name as attribute name.\nMake sure \u0026ldquo;First Row Is Header\u0026rdquo; set to false\nConfigure the input\n CSVString : $flow.OrderString Leave SequenceNumber not mapped  After the data has bean transform to the object which could be recognized by the system. The next step is to convert data to graph entities (nodes, edges and attributes). We use the core activity \u0026ldquo;Build Graph\u0026rdquo; to perform this tranformation. Let's select GraphBuilder -\u0026gt; Bruild Graph and configue it.\nFollow lab1's instruction to turn on the iterator to iterate through upstream output data then map the input data. Here is the mapping\nProduct node\n ProductID -\u0026gt; $iteration[value].ProductID  Employee node\n EmployeeID -\u0026gt; $iteration[value].EmployeeID  Customer node\n CustomerID -\u0026gt; $iteration[value].CustomerID  Order node\n OrderID -\u0026gt; $iteration[value].OrderID CustomerID -\u0026gt; $iteration[value].CustomerID EmployeeID- \u0026gt; $iteration[value].EmployeeID OrderDate -\u0026gt; $iteration[value].OrderDate RequiredDate -\u0026gt; $iteration[value].RequiredDate ShippedDate -\u0026gt; $iteration[value].ShippedDate ShipVia -\u0026gt; $iteration[value].ShipVia Freight -\u0026gt; $iteration[value].Freight ShipName -\u0026gt; $iteration[value].ShipName ShipAddress -\u0026gt; $iteration[value].ShipAddress ShipCity -\u0026gt; $iteration[value].ShipCity ShipRegion -\u0026gt; $iteration[value].ShipRegion ShipPostalCode - \u0026gt; $iteration[value].ShipPostalCode ShipCountry -\u0026gt; $iteration[value].ShipCountry  Suborder node\n OrderID -\u0026gt; $iteration[value].OrderID ProductID -\u0026gt; $iteration[value].ProductID UnitPrice -\u0026gt; $iteration[value].UnitPrice Quantity -\u0026gt; $iteration[value].Quantity Discount -\u0026gt; $iteration[value].Discount  Region node\n RegionName -\u0026gt; $iteration[value].RegionName Country -\u0026gt; $iteration[value].Country  Since one order can be splited to multiple order events (with different product sold). We create two types of order nodes 1. Odrer node with OrderID as its primary key and 2. Suborder node with OrderID, ProductID as primary key. All Suborder nodes connect to Order node by OrderID. (See following screenshot)\nOrder :\nSuborder :\nFollow lab1's instruction to add TGDBUpsert activity\nSelect Connetion\nMap input data\nNow adding a new type of activity called SSEEndPoint which sends graph entities to SSEServer for serving streaming client.\nSelect SSEEndPoint activity from GraphBuilder_SSE.\nSelect \u0026ldquo;SSEConnection\u0026rdquo; we created and used in SSEServer then SSEEndPoint is connected to SSEServer now.\nSetup SessionId to \u0026ldquo;order\u0026rdquo; so the complete URI to access to this event flow would be /sse/order\nMap input data to Graph object from BuildGraph activity\nWe can add log and GraphtoFile activities like previous configured flow.\nNow we have finish last flow for Northwind application.\nThis is the final version of flogo Northwind application\n","excerpt":"Now let's create an application which and receive real-time order events from Kafka topic then build …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/labs/lab-3/","title":"Lab3 - real-time"},{"body":"In following labs we are going to use the Northwind dataset to create an flogo application. The Northwind data is a sample dataset used by Microsoft to demonstrate the features of Microsoft's relational database. We will demonstrate how to use GraphBuilder to convert relational data to graph then insert into TIBCO® Graph Database (TGDB).\nYou can check out or download Project GraphBuilder from https://https://github.com/TIBCOSoftware/labs-graphbuilder-contrib.gitlabs-graphbuilder-contrib.git. You can find the artifacts which you need for the labs project\n /TIBCOSoftware/labs-graphbuilder-contrib/dist : GraphBuilders user extensions /TIBCOSoftware/labs-graphbuilder-contrib/labs : Project data, graph model and TGDB configuration  In the labs we use TIBCO Flogo® Enterprise studio to configure the application. You need to have it installed before you can start building the application.\nImport all required user extensions files (builder.zip, tgdb.zip, tools.zip and sse.zip)\n In \u0026ldquo;Extensions\u0026rdquo; tab click \u0026ldquo;Upload\u0026rdquo; button Click \u0026ldquo;From a Zip file\u0026rdquo; Select one user extension from dist folder (/TIBCOSoftware/labs-graphbuilder-contrib/dist) Click \u0026ldquo;Upload and compiling\u0026rdquo;  Click \u0026ldquo;Done\u0026rdquo; when extension get uploaded and compiled\nUploaded extension will be display on left panel\nKeep uploading all other required extensions. Here is all four required user extensions\n GraphBuilder GraphBuilder_TGDB GraphBuilder_Tools GraphBuilder_SSE  Now you are good to go for the upcoming labs\n","excerpt":"In following labs we are going to use the Northwind dataset to create an flogo application. The …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/labs/","title":"Labs"},{"body":"Implementation Sources\n Connector BuildGraph GraphToFile  ","excerpt":"Implementation Sources\n Connector BuildGraph GraphToFile  ","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/","title":"Components"},{"body":"This example uses Meetup open event through Meetup API see https://www.meetup.com/meetup_api/\nCreate Graph Model Setting  Graph Name: -\u0026gt; Meetup Model Source: -\u0026gt; Select Local File Graph Model: -\u0026gt; Select sample-applications/Meetup_Event/Model_Meetup.json  Create Connection for subscribing Meetup open event Setting  Connection Name: -\u0026gt; Meetup_Event Outbound: -\u0026gt; Sellect \u0026ldquo;true\u0026rdquo; for connecting to Meetup service Server URL: -\u0026gt; http://stream.meetup.com/ Resource Name: -\u0026gt; 2/open_events Access Token: -\u0026gt; not required for accessing open event  Create Connection for serving streaming graph data Setting  Connection Name: -\u0026gt; EventServer Outbound: -\u0026gt; select \u0026ldquo;false\u0026rdquo; since it's a server Server port: -\u0026gt; any available port (8888 for this example) Path: -\u0026gt; /sse/ (client connect http://[host]:[port]/sse/meetup to subscribe \u0026ldquo;meetup\u0026rdquo; graph stream)  Create GraphModel for Enriching Meetup Graph Setting  Graph Name: -\u0026gt; GeographyInfo Model Source: -\u0026gt; Select Local File Graph Model: -\u0026gt; Select sample-applications/Meetup_Event/Model_GeographyInfo.json  Create Application Create Flow for consuming Meetup open event Configure flow inputs and outputs  input sample  {\r\u0026quot;EventString\u0026quot; : \u0026quot;\u0026quot;\r}\rAdd Activity 1 Select GraphBuilder_Tools -\u0026gt; JSONDeserializer\n JSON Data Sample: -\u0026gt; Select sample-applications/Meetup_Event/.json Default Values: -\u0026gt; Set \u0026ldquo;na\u0026rdquo; as default for venue.address_1, category.name  Add Activity 2 Select GraphBuilder_Builder -\u0026gt; BuildGraph\n Graph Model: -\u0026gt; Select \u0026ldquo;Meetup\u0026rdquo; (the connection we created previously) Configure Model: -\u0026gt; Map attributes to input data fields (for nodes and edges)  Add Activity 3-1 Select GraphBuilder_SSE -\u0026gt; SSEEndPoint\n SSE Connection: -\u0026gt; Select \u0026ldquo;EventServer\u0026rdquo; for serving streaming data(the connection we created previously) Avtivity Input 1: set StreamId to \u0026ldquo;meetup\u0026rdquo; (the resource name for client to subscribe) Avtivity Input 2: map required Data object to $activity[BuildGraph].Graph (output of BuildGraph activity)  Add Activity 3-2 Select GraphBuilder_TGDB -\u0026gt; TGDBUpsert\n TGDB Connection: -\u0026gt; Select \u0026ldquo;TGDB\u0026rdquo; for upserting streaming data to TGDB(the connection we created in TGDB_RESTful_Service sample application) Avtivity Input 1: set required Graph object to $activity[BuildGraph].Graph  Add a trigger Select GraphBuilder_SSE -\u0026gt; SSESubscriber\n SSE Connection(outbound request): -\u0026gt; Select \u0026ldquo;Meetup_Event\u0026rdquo; for consuming open event from Meetup web site Flow Input: -\u0026gt; Map EventString to $trigger.Event (This is the output of SSESubscriber)  Create Flow for Serving Streaming Graph Data Configure flow inputs and outputs No configuration is required here since the data flow comes from SSEEndPoint of Meetup Event Flow directly\nAdd a trigger GraphBuilder_SSE -\u0026gt; SSESubscriber\n  SSE Connection(inbound requests): -\u0026gt; Select \u0026ldquo;EventServer\u0026rdquo; for serving streaming data(so now SSEEndPoint connected)\n  Flow Input: -\u0026gt; Map EventString to $trigger.Event (This is the output of SSESubscriber)\n  Incoming Query\n  HTTP GET with resource path /sse/{streamId}\n reply  $flow.queryResult\nsample :\n{\r\u0026quot;graph\u0026quot;:{\r\u0026quot;edges\u0026quot;:{},\r\u0026quot;id\u0026quot;:\u0026quot;GeographyInfo\u0026quot;,\r\u0026quot;model\u0026quot;:{\r\u0026quot;edges\u0026quot;:{\r\u0026quot;attrTypeMap\u0026quot;:{\u0026quot;in_Continent\u0026quot;:{}},\r\u0026quot;directionMap\u0026quot;:{\u0026quot;in_Continent\u0026quot;:1},\r\u0026quot;keyMap\u0026quot;:{\u0026quot;in_Continent\u0026quot;:null},\r\u0026quot;types\u0026quot;:[\u0026quot;in_Continent\u0026quot;],\r\u0026quot;vertexes\u0026quot;:{\u0026quot;in_Continent\u0026quot;:[\u0026quot;City\u0026quot;,\u0026quot;Continent\u0026quot;]}\r},\r\u0026quot;nodes\u0026quot;:{\r\u0026quot;attrTypeMap\u0026quot;:{\u0026quot;Continent\u0026quot;:{\u0026quot;Name\u0026quot;:\u0026quot;String\u0026quot;},\u0026quot;Country\u0026quot;:{\u0026quot;Country_Code\u0026quot;:\u0026quot;String\u0026quot;}},\r\u0026quot;keyMap\u0026quot;:{\u0026quot;Continent\u0026quot;:[\u0026quot;Name\u0026quot;],\u0026quot;Country\u0026quot;:[\u0026quot;Country_Code\u0026quot;]},\u0026quot;types\u0026quot;:[\u0026quot;Country\u0026quot;,\u0026quot;Continent\u0026quot;]\r}\r},\r\u0026quot;modelId\u0026quot;:\u0026quot;GeographyInfo\u0026quot;,\r\u0026quot;nodes\u0026quot;:{\r\u0026quot;Continent_0ecff3229a1a13980689def44b2c66e1\u0026quot;:{\r\u0026quot;attributes\u0026quot;:{\u0026quot;Name\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;Name\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;String\u0026quot;,\u0026quot;value\u0026quot;:\u0026quot;North_America\u0026quot;}},\r\u0026quot;key\u0026quot;:[\u0026quot;North_America\u0026quot;],\r\u0026quot;keyAttributeName\u0026quot;:[\u0026quot;Name\u0026quot;],\r\u0026quot;type\u0026quot;:\u0026quot;Continent\u0026quot;\r},\r\u0026quot;Country_5181a8acdef7be40dfbf3ec66bee2b20\u0026quot;:{\r\u0026quot;attributes\u0026quot;:{\u0026quot;Country_Code\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;Country_Code\u0026quot;,\u0026quot;type\u0026quot;:\u0026quot;String\u0026quot;,\u0026quot;value\u0026quot;:\u0026quot;us\u0026quot;}},\r\u0026quot;key\u0026quot;:[\u0026quot;us\u0026quot;],\r\u0026quot;keyAttributeName\u0026quot;:[\u0026quot;Country_Code\u0026quot;],\r\u0026quot;type\u0026quot;:\u0026quot;Country\u0026quot;\r}\r}\r}\r}\rCreate Flow for Enriching Meetup Graph Configure flow inputs and outputs  input sample  {\r\u0026quot;Continent\u0026quot;: {\r\u0026quot;Name\u0026quot;: \u0026quot;North_America\u0026quot;,\r\u0026quot;Countries\u0026quot;: [\r\u0026quot;us\u0026quot;\r]\r}\r}\rAdd Activity 1 Select GraphBuilder_Builder -\u0026gt; BuildGraph\n Graph Model: -\u0026gt; Select \u0026ldquo;GeographyInfo\u0026rdquo; (the connection we created previously) Configure Model: -\u0026gt; Map attributes to input data fields (for nodes and edges)  Add Activity 2 Select GraphBuilder_SSE -\u0026gt; SSEEndPoint\n SSE Connection: -\u0026gt; Select \u0026ldquo;EventServer\u0026rdquo; for serving streaming data(the connection we created previously) Avtivity Input 1: set StreamId to \u0026ldquo;GeographyInfo\u0026rdquo; (the resource name for client to subscribe) Avtivity Input 2: map required Data object to $activity[BuildGraph].Graph (output of BuildGraph activity)  Add a trigger (Receive HTTP Message)   Setting1: Set Port to any available one (in this sample 9998)\n  Setting2: Set Method to \u0026ldquo;POST\u0026rdquo;\n  Setting3: Set Path to \u0026ldquo;/geography/{Continent}\u0026rdquo;\n  Output Setting\n  $trigger.pathParams.Continent and $trigger.body\nbody sample :\n{\r\u0026quot;Countries\u0026quot;: [\r\u0026quot;us\u0026quot;\r]\r}\r Flow Input1: Continent.Name map to $trigger.pathParams.Continent Flow Input2: Continent.Countries map to $trigger.body.Countries  Implementation Source stored on GitHub here.\n This example is created in TIBCO Flogo® Enterprise 2.8.0 studio.\n ","excerpt":"This example uses Meetup open event through Meetup API see https://www.meetup.com/meetup_api/\nCreate …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/meetup-event/","title":"Meetup Event"},{"body":"Implementation Sources\n Connector Neo4jUpsert  ","excerpt":"Implementation Sources\n Connector Neo4jUpsert  ","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-neo4j/","title":"Neo4j"},{"body":"Project Graph Builder offers an easy and powerful way of loading data from multiple enterprise data sources into TIBCO® Graph Database in real time to leverage the power of all the business insights that are captured in your data.\nPutting the relationships within your data at the forefront allows you to traverse and understand complex relationships within your business model. Storing data in a graph model allows you to convert complex dynamic data into meaningful business insights.\n","excerpt":"Project Graph Builder offers an easy and powerful way of loading data from multiple enterprise data …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/","title":"Sample Applications"},{"body":"Implementation Sources\n Connector JanusgraphUpsert  ","excerpt":"Implementation Sources\n Connector JanusgraphUpsert  ","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-gremlin/","title":"Gremlin"},{"body":"Create TGDB Connection Create Application Create Flow for querying Metadata Configure flow inputs and outputs  input sample  {\r\u0026quot;queryType\u0026quot; : \u0026quot;\u0026quot;\r}\r output sample  {\r\u0026quot;queryResult\u0026quot;: {\r\u0026quot;content\u0026quot;: {},\r\u0026quot;success\u0026quot;: true,\r\u0026quot;error\u0026quot;: {\r\u0026quot;code\u0026quot;: 101,\r\u0026quot;message\u0026quot;: \u0026quot;Not found\u0026quot;\r}\r}\r}\rAdd activities   Activity 1 : GraphBuilder_TGDB -\u0026gt; TGDBQuery\n  Activity 2 : Default -\u0026gt; Return\n  Add a trigger (Receive HTTP Message)  output  $trigger.pathParams.queryType\n reply  $flow.queryResult\nsample :\n{\r\u0026quot;queryResult\u0026quot;: {\r\u0026quot;content\u0026quot;: {},\r\u0026quot;success\u0026quot;: true,\r\u0026quot;error\u0026quot;: {\r\u0026quot;code\u0026quot;: 101,\r\u0026quot;message\u0026quot;: \u0026quot;Not found\u0026quot;\r}\r}\r}\rCreate Flow for Querying Data Configure flow inputs and outputs  input sample  {\r\u0026quot;queryType\u0026quot; : \u0026quot;\u0026quot;,\r\u0026quot;language\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;queryString\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;traversalCondition\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;endCondition\u0026quot;: \u0026quot;\u0026quot;,\r\u0026quot;traversalDepth\u0026quot;: 1\r}\r output sample  {\r\u0026quot;queryResult\u0026quot;: {\r\u0026quot;content\u0026quot;: {},\r\u0026quot;success\u0026quot;: true,\r\u0026quot;error\u0026quot;: {\r\u0026quot;code\u0026quot;: 101,\r\u0026quot;message\u0026quot;: \u0026quot;Not found\u0026quot;\r}\r}\r}\rAdd activities   Activity 1 : GraphBuilder_TGDB -\u0026gt; TGDBQuery\n  Activity 2 : Default -\u0026gt; Return\n  Add a trigger (Receive HTTP Message)  output  $trigger.pathParams.queryType and $trigger.body\nsample :\n{\r\u0026quot;query\u0026quot;: {\r\u0026quot;language\u0026quot; : \u0026quot;tgql\u0026quot;,\r\u0026quot;queryString\u0026quot; : \u0026quot;@nodetype = 'houseMemberType' and memberName = 'Napoleon Bonaparte';\u0026quot;,\r\u0026quot;traversalCondition\u0026quot; : \u0026quot;@edgetype = 'relation' and relation = 'spouse' and @isfromedge = 1 and @degree = 1;\u0026quot;,\r\u0026quot;endCondition\u0026quot; : \u0026quot;\u0026quot;,\r\u0026quot;traversalDepth\u0026quot; : 1\r}\r}\r reply  $flow.queryResult\nsample :\n{\r\u0026quot;queryResult\u0026quot;: {\r\u0026quot;content\u0026quot;: {},\r\u0026quot;success\u0026quot;: true,\r\u0026quot;error\u0026quot;: {\r\u0026quot;code\u0026quot;: 101,\r\u0026quot;message\u0026quot;: \u0026quot;Not found\u0026quot;\r}\r}\r}\rImplementation Source stored on GitHub here.\n This example is created in TIBCO Flogo® Enterprise 2.8.0 studio.\n ","excerpt":"Create TGDB Connection Create Application Create Flow for querying Metadata Configure flow inputs …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/sample-applications/restful-service/","title":"RESTful Service"},{"body":"Implementation Sources\n Connector SSEEndpoint SSEServer SSESubscriber  ","excerpt":"Implementation Sources\n Connector SSEEndpoint SSEServer SSESubscriber  ","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-sse/","title":"SSE"},{"body":"Implementation Sources\n Connector FileReader Accumulator CSVFileWriter CSVParser JsonDataDecoupler JsonDeserializer JsonParser CSVParser JsonDataDecoupler JsonDeserializer TableQuery TableUpsert  ","excerpt":"Implementation Sources\n Connector FileReader Accumulator CSVFileWriter CSVParser JsonDataDecoupler …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/components/graphbuilder-tools/","title":"Tools"},{"body":"This section is where the user documentation for TIBCO LABS™ Project GraphBuilder - all the information you need to understand this project.\n","excerpt":"This section is where the user documentation for TIBCO LABS™ Project GraphBuilder - all the …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/docs/","title":"Documentation"},{"body":"","excerpt":"","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/index.json","title":""},{"body":" \r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/about/featured-background_hud062541b21b90529446eee6001de80cd_8365555_960x540_fill_q75_catmullrom_bottom.jpg); }\r@media only screen and (min-width: 1200px) {\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/about/featured-background_hud062541b21b90529446eee6001de80cd_8365555_1920x1080_fill_q75_catmullrom_bottom.jpg); }\r}\r\rProject Graph Builder by TIBCO LABS™\rabc line 1 abc line 2 -- \r\r\r\r\r\r\rMore Details about the underlying Product here TIBCO® Graph Database Wiki, on \r\r\r\r\rTIBCO LABS™ is a program designed to provide customers and partners with a mechanism for actively participating in TIBCO’s history of innovation. TIBCO has always been at the forefront of innovation, and TIBCO LABS™ allows participants to share in this history by collaboratively building solutions to today’s challenging problems, previewing new capabilities, and accessing emerging technologies in areas such as blockchain, AI / ML and IoT. Through TIBCO LABS™, customers and partners can gain insight into TIBCO’s innovation activities, participate in shaping the form of these activities in the years to come, and benefit from TIBCO’s leadership position in integration and analytics. \n    \n \r\r \rBSD 3-Clause License  Copyright © 2020 TIBCO Software Inc. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n  Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n  Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n  Neither the name of TIBCO Software Inc. nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT OWNER AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n \r\r ","excerpt":"#td-cover-block-0 {\rbackground-image: …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/about/","title":"About Project Graph Builder"},{"body":"","excerpt":"","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/community/","title":"Community"},{"body":"\r\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/featured-background_hud062541b21b90529446eee6001de80cd_8365555_960x540_fill_q75_catmullrom_top.jpg); }\r@media only screen and (min-width: 1200px) {\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/featured-background_hud062541b21b90529446eee6001de80cd_8365555_1920x1080_fill_q75_catmullrom_top.jpg); }\r}\r\rProject GraphBuilder\rLearn More \r\rDownload \r\rLeveraging the power of relationships in your data\n\n\r\r\r\r\r\r\r\rProject GraphBuilder by TIBCO LABS™\nThe application of graph analytics keeps growing in the market and it is becoming more relevant in today's world. The need to continuously accelerate the data ingestion into graph models to enable fast analysis of complex interrelationships in the data sometimes can be hard to meet. Project Graph Builder by TIBCO LABS™ addresses these challenges by providing an easy and powerful way to load data into TIBCO® Graph Database.\n\r\r\r\r\r\rOverview\rBusiness use case, followed by the Proposed of the Solution.\nRead more …\n\r\r\rComponents\rLearn more about the used TIBCO Products and Assets.\nRead more …\n\r\r\rGet Started\rFollow the documentation, and start today !\nRead more …\n\r\r\r--\r\r\r\r\r\r\rContact us!\rReach us for more details, or engage us today !\nRead more …\n\r\r\rContributions welcome!\rWe do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n\r--\r\r\rFollow us on Twitter!\rFor announcement of latest features etc\u0026hellip;\nRead more …\n\r\r\r\r","excerpt":"#td-cover-block-0 {\rbackground-image: …","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/","title":"Project Graph Builder"},{"body":"","excerpt":"","ref":"https://tibcosoftware.github.io/labs-graphbuilder-contrib/search/","title":"Search Results"}]