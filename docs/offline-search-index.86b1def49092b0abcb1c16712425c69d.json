[{"body":"Implementation Source Download application artifacts from here.\nDownload GraphBuilder user extensions from here\nInstallation Open TIBCO Flogo® Enterprise 2.8.1 studio and upload required user extensions (builder.zip, tgdb.zip and tools.zip)\nCreate an empty application for Airline application\nImport application from the pre-configured Airline application descriptor\nFind and select descriptor (airline.json) from download folder\nIgnore waning just click “Import All”\nAirline application with two data flow (flight and pnr) is imported\nCheck connection tab to see two connections to be fixed\nSelect TGDB connection and edit it\nChange configuration match your TIBCO® Graph Database setup then click “Connect” to save it\nSame to the Graph connection but just click “Connect” since graph model has been correctly set\n This example is created in TIBCO Flogo® Enterprise 2.8.1 studio.\n ","excerpt":"Implementation Source Download application artifacts from here. …","ref":"/labs-graphbuilder-contrib/docs/sample-applications/airline/","title":"Airline"},{"body":" Graph Connector : Graph Connector is a component which hosts your graph model for sharing graph model among graph construction related activity. Activities which connect to the same Graph connector would share same graph model (data schema)  Here is the schema of graph model\n{\r\"$schema\": \"http://json-schema.org/draft-04/schema#\",\r\"type\": \"object\",\r\"properties\": {\r\"nodes\": {\r\"type\": \"array\",\r\"items\": {\r\"type\": \"object\",\r\"properties\": {\r\"name\": {\r\"type\": \"string\"\r},\r\"key\": {\r\"type\": \"array\",\r\"items\": {\r\"type\": \"string\"\r}\r},\r\"attributes\": {\r\"type\": \"array\",\r\"items\": {\r\"type\": \"object\",\r\"properties\": {\r\"name\": {\r\"type\": \"string\"\r},\r\"type\": {\r\"type\": \"string\"\r}\r},\r\"required\": [\r\"name\",\r\"type\"\r]\r}\r}\r},\r\"required\": [\r\"name\",\r\"key\",\r\"attributes\"\r]\r}\r},\r\"edges\": {\r\"type\": \"array\",\r\"items\": {\r\"type\": \"object\",\r\"properties\": {\r\"to\": {\r\"type\": \"string\"\r},\r\"name\": {\r\"type\": \"string\"\r},\r\"from\": {\r\"type\": \"string\"\r},\r\"attributes\": {\r\"type\": \"array\",\r\"items\": {\r\"type\": \"object\",\r\"properties\": {\r\"name\": {\r\"type\": \"string\"\r},\r\"type\": {\r\"type\": \"string\"\r}\r}\r}\r}\r},\r\"required\": [\r\"from\",\r\"name\",\r\"to\",\r\"attributes\"\r]\r}\r}\r}\r}\r   BuildGraph Activity BuildGraph Activity must connect to a Graph Connector so it can build its input data schema from the graph model which is hosted in that Graph connector. BuildGraph activity transform the input data to graph entities (nodes, edges and their attributes) based on the graph model     GraphToFile GraphToFile activity takes graph entities (nodes and edges) from BuildGraph and writes them to a file. It’s a useful utility for troubleshooting    ","excerpt":" Graph Connector : Graph Connector is a component which hosts your …","ref":"/labs-graphbuilder-contrib/docs/components/graphbuilder/","title":"GraphBuilder"},{"body":"Let’s start by building a graph model using the Northwind dataset. In the connection tab, select Graph to host graph model for the Flogo application.\nIn the dialog box\n Set model name Select “Local File” Select and upload northwind_model.json (Northwind model descriptor) from the ‘Download’ folder Click connect  The Northwind model descriptor file has been attached to the graph model\nSelect ‘Apps’ tab and click ‘Create’ button to start building the first application\nName the application “Northwind” and then create it\nSelect ‘Create’ to build it from scratch\nFlogo® Enterprise studio brings the dialog for creating the first flow. Based on the Northwind dataset, five flows are going to be created that will process the data from customers.csv, suppliers.csv, employees.csv, categories.csv and products.csv respectively. First step is building the customer data flow.\nIn the empty flow panel, click “Flow Inputs \u0026 Outputs” vertical bar to generate data schema for current flow.\nThe flow starts by processing CSV data rows from a file one line at a time (to be set up in FileReader Trigger later on). A sample of useful data fields from incoming data need to be set. In the sample, the “FileContent” field represents a row of CSV data and the “LineNumber” field represents the current “sequence number” of the row in question.\nClick the “Save” button so the schema generator of the studio converts the data sample into the schema definition.\nNext, a trigger (data source of the flow) needs to be added by clicking “+” button on the left-hand side. Then select GraphBuilder_Tools -\u003e FileReader trigger.\nFilling the “Trigger Settings”\n Filename: point to the customers.csv in the ‘Download’ folder Asynchronous: set it to true so all the triggers for different data files could run simultaneously Emit per Line: set it to true so only one row of data is sent to the flow Max Number of Line: if it is set to negative, it means there will be no limit  Click “Save” to finish\nSwitch to “Map to Flow Inputs” and make the following mapping\n FileContent (defined in schema) -\u003e $trigger.FileContent LineNumber (defined in schema) -\u003e $trigger.LineNumber  Click “Save” button\nBack to the flow to add first activity to the flow. Select GraphBuilder_Tools -\u003e CSVParser to convert CSV text to system object.\nFilling Settings:\n Date Format Sample: 2006-01-02 (Data format setup for underlining GOLang code) Serve Graph Data: set it to false since it is not going to be used Output Field Names: one line of setting for each data column. AttributeName is the attribute name in generated system object and CSVFieldName is the column name in CSV data row. Set optional to “false” for all key element fields. Click “Save” after finish configuring each line. First Row is Header: It can be set to true since the data file that is being used has a header  Click “Save” button\nSwitch to Inputs and map current input data to output data from upstream\n CSVString -\u003e $flow.FileContent SequenceNumber -\u003e $flow.LineNumber  Click “Save” when finishing it\nNow the data has been transformed to the system object which could be recognized by the system. The next step is to convert plain object data to graph entities (nodes, edges and their attributes). We are going to use the core activity called “BuildGraph” to perform this transformation.\nLet’s select GraphBuilder -\u003e Build Graph and configue it.\nFilling setting\n Graph Model: Select “Northwind” connector which we just created. The “Northwind” graph model now associated with this activity which means BuildGraph activity take “Northwind” graph model to build the structure of its input data schema. This is seen during the setting of “Inputs” data mapping later. Allow Null Key: setting it to “true” will make it generate nodes (even when their primary key contains null elements). Batch Mode: set it to “false” since one data batch is processed each time. Pass Through Fields: leave it empty Modify Size of Instances: leave it empty, will be used in Employee data setup  Click “Save” button\nBefore input data can be mapped, take a look at the output schema of “CSVParser” (it’s the upstream data for current “BuildGraph” activity). “CSVParser” has ability to handle multiple CSV rows, the output data structure is an array of object not just a single object.\nIn order to process the incoming data of array type, the iterator needs to be turned on to iterate through upstream output data (even though in this example there is only one element in the array). Following screenshot shows how to do it.\nWhile mapping the input data, you may notice that the “Northwind” graph model has been brought to this activity as an input schema and the mapping target is not to “CSVParser” anymore but the local iteration. For the data coming from customers.csv, more than one type of nodes can be populated (which are defined in Northwind graph). Here is how the nodes (Customer, Company and Region) will be set\nCustomer node\n _skipCondition -\u003e null==$iteration[value].CustomerID CustomerID -\u003e $iteration[value].CustomerID CustomerName -\u003e $iteration[value].CustomerName ContactName -\u003e $iteration[value].ContactName ContactTitle -\u003e $iteration[value].ContactTitle City -\u003e $iteration[value].City RegionName -\u003e $iteration[value].RegionName RegionCode -\u003e $iteration[value].RegionCode Country -\u003e $iteration[value].Country Phone -\u003e $iteration[value].Phone Fax -\u003e $iteration[value].Fax  Company node\n _skipCondition -\u003e null==$iteration[value].CompanyID CompanyID -\u003e $iteration[value].CompanyID CompanyName -\u003e $iteration[value].CompanyName  Region node\n RegionName -\u003e $iteration[value].RegionName Country -\u003e $iteration[value].Country  Mapping for edge doesn’t need to be set up if there are no attributes for it (we don’t configure “label” attribute for edges now since TGDB doesn’t need it). BuildGraph activity is going to use the edge defined in graph model to create edge between nodes automatically.\nAfter we convert data to graph entities, we can insert them to TIBCO® Graph Database. Let’s create TIBCO® Graph Database connection first. In “Connections” tab select Add Connection -\u003e TGDB Connector\nIn the dialog box enter the following information\n Connection name (for example “TGDB”) TGDB Server URL Username Password Keep Connection Alive: select “true”  Click “Connect” button\nNow back to application’s “Customer Data” flow to add TGDB activity. Select GraphBuilder_TGDB -\u003e TGDBUpsert.\nFilling Setting for\n TGDB connection: Select the “TGDB” Connection we just created Set Allow empty sting key to true (so a node with empty string key still get inserted)  Click “Save”\nMap input data\n Graph{} - $activity[BuildGraph].Graph{}  Since the Graph object is immutable, you are not allowed to access the detail of its internal structure.\nA built-in “Log” activity can be inserted by following the next steps: Make room for “Log” activity by shifting activities one position to the right.\nAdd “Log” activity by select Default -\u003e Log\nSetup message for printing (you can apply built-in function to incoming data fields)\n message : string.concat(string.tostring($flow.LineNumber), \" - “, $flow.FileContent)  You can write the entities (which are generated by BuildGraph activity) to file by adding GraphBuilder -\u003e GraphtoFile activity\nSpecify the output folder and filename for GraphtoFile activity\nInput data is and only can be Graph. The input setup same as TGDBUpsert\nCongratulations, you have finished the first data flow for the application\nNow you can follow the same steps to finish all the rest of flows\nWhen you work on “Employee flow”, please pay attention to following steps.\nIn employee data there are two fields called EmployeeID and ReportTo each of them represents one individual employee. It implies that from the information of one employee data we can populate two employee nodes. One for employee himself/herself and the other one for his/her manager. We have to increase the instance of employee node for such data mapping.\n Modify size of instances: Add one entry for “Employee” node and set the number of instances to 2  Click “Save”\nSwitch to Inputs you will see two employee nodes appears (Employee0 and Employee1). Let’s make Employee0 the employee (not manager) so all data can be populated to this node.\nWe make the Employee1 node represent the manager of Employee0 node so the only information we have for it (in the data) is “ReportTo” which will populate Employee1’s EmployeeID.\nThen we need to tell BuildGrap activity the relation between Employee0 and Employee1.\nNow we can test Northwind application by sending data to it and then verifying if the data got inserted into TIBCO® Graph Database server\nFor building Northwind Flogo application, follow the next steps\n In project, click “Build” button Select the build target OS (in my case Darwin/amd64) then click to build  Once finished you can get your executable (Northwind-darwin_amd64) in the browser download folder\nTIBCO® Graph Database needs to be set up next. Currently, Project GraphBuilder only supports TIBCO® Graph Database 2.0.1 (both Enterprise Edition and Community Edition are supported). You can get a Community version from here.\nFollow the instructions in the download file to install TIBCO® Graph Database server and then copy the artifacts from the Download folder\n Northwind/tgdb/northwind -\u003e tgdb/2.0/examples Northwind/tgdb/init_northwind_with_data_definition.sh -\u003e tgdb/2.0/bin/ Northwind/tgdb/run_northwind.sh -\u003e tgdb/2.0/bin/  In Terminal switch to tgdb/2.0/bin folder then\n execute ./init_northwind_with_data_definition.sh to initialize tgdb with Northwind schema   execute ./run_northwind.sh to run tgdb server  Open a new terminal and switch to the folder which contains Northwind application executable (Northwind-darwin_amd64).\n Change Northwind-darwin_amd64’s permission to executable Run Northwind-darwin_amd64  Open a new Terminal and switch to TIBCO® Graph Database bin folder\n run tgdb-admin make query to get all categories  We’ve proved that data has been inserted to TIBCO® Graph Database server\n","excerpt":"Let’s start by building a graph model using the Northwind dataset. In …","ref":"/labs-graphbuilder-contrib/docs/labs/lab-1/","title":"Lab1 - CSV"},{"body":"Implementation Source Download application artifacts from here.\nDownload GraphBuilder user extensions from here\nInstallation Open TIBCO Flogo® Enterprise 2.8.1 studio and upload required user extensions (builder.zip, sse.zip, tgdb.zip and tools.zip)\nFollow the Airline example to continue importing application\nCreate application from scratch see labs\n This example is created in TIBCO Flogo® Enterprise 2.8.0 studio.\n ","excerpt":"Implementation Source Download application artifacts from here. …","ref":"/labs-graphbuilder-contrib/docs/sample-applications/northwind/","title":"Northwind"},{"body":"Using GraphBuilder you can build your own application to do the following:\n Transform your data to the desired graph structure based upon an existing graph model. Insert graph data into any major graph database in the market (including TIBCO® Graph Database, Dgraph, Neo4j and JanusGraph). Query and delete graph data against TIBCO® Graph Database  ","excerpt":"Using GraphBuilder you can build your own application to do the …","ref":"/labs-graphbuilder-contrib/docs/overview/","title":"Overview"},{"body":" Download latest TIBCO Flogo® Enterprise here Download GraphBuilder user extensions here Import GraphBuilder user extensions to TIBCO Flogo® Enterprise studio (for detail, see instructions in the Labs section) Enjoy it!  ","excerpt":" Download latest TIBCO Flogo® Enterprise here Download GraphBuilder …","ref":"/labs-graphbuilder-contrib/docs/getting-started/","title":"Getting Started"},{"body":"Implementation Source Download application artifacts from here.\nDownload GraphBuilder user extensions from here\nInstallation Open TIBCO Flogo® Enterprise 2.8.1 studio and upload required user extensions (builder.zip, tgdb.zip and tools.zip)\nFollow the Airline example to continue importing application\n This example is created in TIBCO Flogo® Enterprise 2.8.1 studio.\n ","excerpt":"Implementation Source Download application artifacts from here. …","ref":"/labs-graphbuilder-contrib/docs/sample-applications/hierachy/","title":"Hierachy"},{"body":"Create a new Flogo application called “TGDB_RESTful_Service”\nClick “+ Create” button to build from scratch\nCreate the first flow for querying metadata\nDefine the data schema for the input of current flow sample data (queryType in string data type).\n queryType: the value could be “metadata”, “edgetypes” or “nodetypes” (metadata querying flow)  Saving sample data will evoke schema builder to generate the schema definition from it\nDefine the output schema for the current flow by pasting sample output data\n Content: contains the data of query result Success: true means query go through without error Code: error code Message: error message  Click “Save” button\nClicking “Save” button triggers schema definition generation\nAdd a trigger to receive HTTP request by clicking “+” -\u003e “ReceiveHTTPMessage”\nSelect GET, enter resource path “/tgdb/{queryType}” then click “Finish”\nNow we have a trigger with HTTP GET methods and listen on port 9999)\nClick the icon of trigger to map incoming query data to flow input data\nIn “Reply Settings” set reply schema make it same as flow output data schema\nIn “Map from flow outputs” mapping data.queryResult to $flow.queryResult\nAdd query activity by selecting GraphBuilder_TGDB -\u003e TGDBQuery activity\nSelect the “TGDB” connection that was created in Lab1 so the TGDBQuery activity executes against the server where the Northwind data was inserted\nMap input data for TGDBQuery activity\n QueryType : $flow.queryType  Add return activity to link the query result back to HTTP trigger\nMap outputs for Return activity\n queryResult : $activity[TGDBQuery].queryResult (map entire object)  You’ve finished creating metadata query flow\nClick “Create” button to create another flow for querying the content of Northwind graph\nAdd a name and description for the new flow\nDefine the flow inputs data schema by pasting sample data (for schema detail; see TGDB documentation)\n queryType: search (for content flow) language: TGQL (TIBCO graph query language) or Gremlin queryString: for TGQL and Gremlin traversalCondition: TGQL only traversalDepth: TGQL only  Click save to generate data schema definition\nFlow output data schema same as metadata flow\nAdd another trigger for receiving content query\nPOST method for content query\nAdding sample query for the output (to the flow) setting. To be noticed that the schema is very similar to flow input schema but grouped under “query” keyword.\nMap to flow input\n queryType: $trigger.pathParams.queryType language: $trigger.body.query.language queryString: $trigger.body.query.queryString traversalCondition: $trigger.body.query.traversalCondition endCondition: $trigger.body.query.endCondition traversalDepth: $trigger.body.query.traversalDepth  Click save\nSet the reply data (same as metadata flow)\nAdd query activity by select GraphBuilder_TGDB -\u003e TGDBQuery activity\nSelect “TGDB” connection that was created in Lab1 so the TGDBQuery activity queries the same server updated Northwind data was inserted into\nMap input data for TGDBQuery activity\n QueryType: $flow.queryType params.language: $flow.language params.queryString: $flow.queryString params.traversalCondition: $flow.traversalCondition params.endCondition: $flow.endCondition params.traversalDepth: $flow.traversalDepth  Add “Return” activity to link the query result back to HTTP trigger\nMap outputs for Return activity\n queryResult: $activity[TGDBQuery].queryResult (map entire object)  The TGDB_RESTful_Service is configured and it’s ready for query Nothwind graph\nTest TGDB_RESTful_Service so you can see Nothwind data after querying against TGDB server\nFor building Flogo application\n In project click “Build” button Select the build target OS (in my case Darwin/amd64) then click to build  Once finished you can get your executable in your browser’s download folder\nFind your executable and change its permission to executable then run it\nSwitch to local labs -\u003e utilities -\u003e lite folder\n Launch UI tool by type “npm start” It is required to have npm and lite-server installed before using this tool  Upon launching the server, the default browser will pop up and show Project GraphBuilder UI utility. For querying data against TGDB server, click “TGDB Data” tab\nA query to TGDB using TGQL expression can be made as shown in screenshot below\nNow, Northwind data from TGDB server can be seen\n","excerpt":"Create a new Flogo application called “TGDB_RESTful_Service”\nClick “+ …","ref":"/labs-graphbuilder-contrib/docs/labs/lab-2/","title":"Lab2 - Query"},{"body":" TGDB Connector : A TGDB connector is a component to store TIBCO® Graph Database server connection information. Activities which connect to the same TGDB connector are actually connecting to the same TIBCO® Graph Database server instance TGDBUpsert : A TGDBUpsert activity consumes the graph entities from BuildGraph activity and inserts/updates them to TIBCO® Graph Database TGDBQuery : With TGDBQuery activity users can build their own application to query against TIBCO® Graph Database. It supports both TGQL and Gremlin query language TGDBDelete : TGDBDelete activity implements the deletion of graph entities for TIBCO® Graph Database. It takes graph entities (with primary key attributes populated) from BuildGraph then performs the deletion on them  ","excerpt":" TGDB Connector : A TGDB connector is a component to store TIBCO® …","ref":"/labs-graphbuilder-contrib/docs/components/graphbuilder-tgdb/","title":"TGDB"},{"body":" Connector : A Dgraph connector is a component to store your Dgraph server connection information. Activities which connect to the same Dgraph connector would connect to the same Dgraph server instance DgraphUpsert : A DgraphUpsert activity consumes the graph entities from BuildGraph activity and inserts/updates them to Dgraph server  ","excerpt":" Connector : A Dgraph connector is a component to store your Dgraph …","ref":"/labs-graphbuilder-contrib/docs/components/graphbuilder-dgraph/","title":"Dgraph"},{"body":"Implementation Source Download application artifacts from here.\nDownload GraphBuilder user extensions from here\nInstallation Open TIBCO Flogo® Enterprise 2.8.1 studio and upload required user extensions (builder.zip, dgraph.zip and tools.zip)\nFollow the Airline example to continue importing application\n This example is created in TIBCO Flogo® Enterprise 2.8.1 studio.\n ","excerpt":"Implementation Source Download application artifacts from here. …","ref":"/labs-graphbuilder-contrib/docs/sample-applications/iot-data-consumer/","title":"IoT Data Consumer"},{"body":"Create an application which receives real-time order events from Kafka topic then build graph entities (nodes, edges and their attributes), insert/update entities to TGDB then serve real-time graph entities as a streaming server.\nCreate an internal “Server Sent Event (SSE)” connection to link between order event flow and SSE server flow (for serving streaming graph entities to external client).\nIn “Connections” tab select GraphBuilder_SSE -\u003e Server-sent Events Connection\nConnection settings (the settings below match the client tool which is provided for browsing real-time graph entity update)\n Connection Name: Set name to “EventServer” Outbound: Set false as it’s a server Server port: 8888 Path: It’s URI path “/sse/” TLS enabled: false  Click “Connect”\nBack to Northwind application to create a new flow called “Order Event Server”\nSelect a “SSE Server” trigger to serve graph entities (come from order event flow) for streaming client\nSettings\n Connection Name: Select the “EventServer” connection which we just created  Click “Save”.\nThis simple flow will be serving streaming graph entities.\nAdd the last flow for Northwind application. It is “Order Data Flow” which listen to Kafka topic to consume order events as input data of the flow.\nBefore it is created, a “Kafka Connection” needs to be created. In connection tab select “Apache Kafka Client Configuration”.\nConfigure Apache Kafka Client as the following screenshot and then save it.\nBack to the application, create a new flow called “Order Event”.\nClick “Flow Inputs \u0026 Outputs” (vertical blue bar) to define a schema between flow and trigger. Set the following data sample and then click save.\nAfter clicking save button, the schema generator converts sample data to schema definition.\nClick “+” to add trigger (Kafka Consumer).\nSelect the “Northwind Orders” configuration that was just created and then click continue.\nSelect “Just Add Trigger” button to add a trigger.\nFinish setting up the trigger as shown in screenshot below.\nMap OrderString to $trigger.stringValue\nAdd CSVParser to convert incoming CVS string to system object.\nFollow the instruction in Lab1 to define the mapping between CSV fields and attribute of system object. Use the column field name as attribute name.\nMake sure “First Row Is Header” set to false.\nConfigure the input\n CSVString : $flow.OrderString Leave SequenceNumber not mapped  After the data has been transformed to the object which could be recognized by the system, convert data to graph entities (nodes, edges and their attributes). Use core activity “Build Graph” to perform this transformation. Let’s select GraphBuilder -\u003e Build Graph and configure it.\nFollow Lab1 instruction to turn on the “iterator” for iterating through upstream output data (at runtime) and then map with input data of BuildGraph activity. Here is the mapping\nProduct node\n ProductID -\u003e $iteration[value].ProductID  Employee node\n EmployeeID -\u003e $iteration[value].EmployeeID  Customer node\n CustomerID -\u003e $iteration[value].CustomerID  Order node\n OrderID -\u003e $iteration[value].OrderID CustomerID -\u003e $iteration[value].CustomerID EmployeeID- \u003e $iteration[value].EmployeeID OrderDate -\u003e $iteration[value].OrderDate RequiredDate -\u003e $iteration[value].RequiredDate ShippedDate -\u003e $iteration[value].ShippedDate ShipVia -\u003e $iteration[value].ShipVia Freight -\u003e $iteration[value].Freight ShipName -\u003e $iteration[value].ShipName ShipAddress -\u003e $iteration[value].ShipAddress ShipCity -\u003e $iteration[value].ShipCity ShipRegion -\u003e $iteration[value].ShipRegion ShipPostalCode - \u003e $iteration[value].ShipPostalCode ShipCountry -\u003e $iteration[value].ShipCountry  Suborder node\n OrderID -\u003e $iteration[value].OrderID ProductID -\u003e $iteration[value].ProductID UnitPrice -\u003e $iteration[value].UnitPrice Quantity -\u003e $iteration[value].Quantity Discount -\u003e $iteration[value].Discount  Region node\n RegionName -\u003e $iteration[value].RegionName Country -\u003e $iteration[value].Country  Since one order can be split into multiple order events (with different product sold), create two types of order nodes:\n Odrer node (main order) with OrderID as its primary key Suborder node with OrderID, ProductID as primary key.  BuildGraph activity would link (via edge) all Suborder nodes to Order node by matching their the OrderID (see following screenshot).\nOrder :\nSuborder :\nFollow Lab1’s instruction to add TGDBUpsert activity\nSelect Connetion\nMap input data\nNow adding a new type of activity called SSEEndPoint which sends graph entities to SSEServer for serving streaming client.\nSelect SSEEndPoint activity from GraphBuilder_SSE.\nSelect “SSEConnection” we created and used in SSEServer earlier then the new SSEEndPoint is connected to SSEServer now.\nSetup SessionId to “order” so the complete URI to access to this event flow would be /sse/order\nMap input data to Graph object from BuildGraph activity\nAdd log and GraphtoFile activities like previous configured flows\nThis completes the last flow for the Northwind application.\nThis is the final version of the Flogo Northwind application\nRebuild application for further testing\nInstall Kafka Message Bus to provide order event. Here are the installation instructions.\nAfter downloading Kafka Message Bus and installing Kafka, start it\n Start zoo keeper   Start server   Create “test” topic  Restart Northwind application executable.\n Switch to the folder which contains Northwind application executable (Northwind-darwin_amd64). Change Northwind-darwin_amd64’s permission to executable Run Northwind-darwin_amd64  There will be two extra messages while Northwind application starting\n Kafka consumer (the trigger of order event flow) is up and listening SSEServer is up and waiting for client (UI utility) to connect  Here is the test (see screenshot)\n Ensure TGDB, TGDB_RESTful_Service, Kafka (server, zoo keeper, producer) and UI utility are running On the upper/middle left of screenshot open oerders.csv file On the lower left of screenshot start Kafka producer and keep it opened On the right follow the instruction to 1. Click “Realtime Data” 2. Click “Connect” to connect to SSE server in Northwind application 3. Copy \u0026 paste order to Kafka producer then press enter 4 ~ 6. Each time you send one order you will see the corresponding graph entities showing on the UI.  Send as many orders as wished.\nAfter the streaming testing, see the order in TGDB. Follow the instructions in Lab2\n Click “TGDB Data” button Use the default query setup but make traversalDepth = 5 Click “Make Query” button  You’ll see the oder with OrderID = 10248 and its associated graph entities on the UI\nThe last test is about traversal query. Find all companies which supply products within the order from the company ‘Vins et alcools Chevalier’. We are going to use Postman and TGDB_RESTful_Service to query against TGDB server\n Open a postman and setup a POST query The gremlin query is “g.V().has(‘Company’, ‘CompanyID’, ‘Vins et alcools Chevalier’).in(‘Customer_Company’).in(‘SoldTo’).out(‘Includes’).out(‘Contains’).in(‘Supplies’).out(‘Supplier_Company’);” You should get “Formaggi Fortini s.r.l.\", “Leka Trading” and “Cooperativa de Quesos ‘Las Cabras’” in your result  Observe the traversal request on the UI utility and verify the correctness of the query\nCongratulations! This concludes the three Labs\n","excerpt":"Create an application which receives real-time order events from Kafka …","ref":"/labs-graphbuilder-contrib/docs/labs/lab-3/","title":"Lab3 - real-time"},{"body":"The following section provides step-by-step, hands-on exercises that show how to build a Flogo application by parsing data coming in CSV files and inserting it to TIBCO® Graph Database.\nThe Labs leverage the Northwind dataset (sample dataset used by Microsoft to demonstrate the features of their relational database). The exercises illustrate how GraphBuilder can be used to convert relational data into graph and then insert it into TIBCO® Graph Database.\n Project GraphBuilder and the artifacts needed for the exercises can be downloaded here Click here to download GraphBuilder user extensions Click here to download the project data, graph model and TGDB configuration Click here to download the GUI utilities  The Labs use TIBCO Flogo® Enterprise studio to configure the applications. It is required to have it locally installed before starting building the application. Click here to download TIBCO Flogo® Enterprise studio\nAfter the installation of TIBCO Flogo® Enterprise studio has been completed, import all required user extensions files (builder.zip, tgdb.zip, tools.zip and sse.zip) as shown in the image below\n In “Extensions” tab click “Upload” button Click “From a Zip file” Select one user extension (for example builder.zip) from your download folder at a time Click “Upload and compiling”  Click “Done” when extensions are uploaded and compiled\nUploaded extension will be display on left panel\nKeep uploading all other required extensions. Here are required user extensions\n GraphBuilder GraphBuilder_TGDB GraphBuilder_Tools GraphBuilder_SSE  This completes the set up for the Labs\n","excerpt":"The following section provides step-by-step, hands-on exercises that …","ref":"/labs-graphbuilder-contrib/docs/labs/","title":"Labs"},{"body":" Graph Connector: Graph connector is a component which hosts a graph model for sharing throughout graph construction related activities. The activities that connect to the same Graph connector share the same graph model (data schema) BuildGraph Activity: A BuildGraph Activity must connect to a Graph Connector to build the input data schema from the graph model which is hosted in the Graph Connector. BuildGraph Activity transforms the input data into graph entities (nodes, edges and their attributes) based on the graph model. TGDB Connector: A TGDB Connector is the component that stores TIBCO® Graph Database server connection information. Activities which connect to the same TGDB Connector are connecting to the same TIBCO® Graph Database server instance TGDBUpsert: A TGDBUpsert activity consumes the graph entities from a BuildGraph Activity and inserts/updates them into TIBCO® Graph Database  ","excerpt":" Graph Connector: Graph connector is a component which hosts a graph …","ref":"/labs-graphbuilder-contrib/docs/components/","title":"Components"},{"body":"This example uses Meetup open event through Meetup API see https://www.meetup.com/meetup_api/\nCreate Graph Model Setting  Graph Name: -\u003e Meetup Model Source: -\u003e Select Local File Graph Model: -\u003e Select sample-applications/Meetup_Event/Model_Meetup.json  Create Connection for subscribing Meetup open event Setting  Connection Name: -\u003e Meetup_Event Outbound: -\u003e Sellect “true” for connecting to Meetup service Server URL: -\u003e http://stream.meetup.com/ Resource Name: -\u003e 2/open_events Access Token: -\u003e not required for accessing open event  Create Connection for serving streaming graph data Setting  Connection Name: -\u003e EventServer Outbound: -\u003e select “false” since it’s a server Server port: -\u003e any available port (8888 for this example) Path: -\u003e /sse/ (client connect http://[host]:[port]/sse/meetup to subscribe “meetup” graph stream)  Create GraphModel for Enriching Meetup Graph Setting  Graph Name: -\u003e GeographyInfo Model Source: -\u003e Select Local File Graph Model: -\u003e Select sample-applications/Meetup_Event/Model_GeographyInfo.json  Create Application Create Flow for consuming Meetup open event Configure flow inputs and outputs  input sample  {\r\"EventString\" : \"\"\r}\rAdd Activity 1 Select GraphBuilder_Tools -\u003e JSONDeserializer\n JSON Data Sample: -\u003e Select sample-applications/Meetup_Event/.json Default Values: -\u003e Set “na” as default for venue.address_1, category.name  Add Activity 2 Select GraphBuilder_Builder -\u003e BuildGraph\n Graph Model: -\u003e Select “Meetup” (the connection we created previously) Configure Model: -\u003e Map attributes to input data fields (for nodes and edges)  Add Activity 3-1 Select GraphBuilder_SSE -\u003e SSEEndPoint\n SSE Connection: -\u003e Select “EventServer” for serving streaming data(the connection we created previously) Avtivity Input 1: set StreamId to “meetup” (the resource name for client to subscribe) Avtivity Input 2: map required Data object to $activity[BuildGraph].Graph (output of BuildGraph activity)  Add Activity 3-2 Select GraphBuilder_TGDB -\u003e TGDBUpsert\n TGDB Connection: -\u003e Select “TGDB” for upserting streaming data to TGDB(the connection we created in TGDB_RESTful_Service sample application) Avtivity Input 1: set required Graph object to $activity[BuildGraph].Graph  Add a trigger Select GraphBuilder_SSE -\u003e SSESubscriber\n SSE Connection(outbound request): -\u003e Select “Meetup_Event” for consuming open event from Meetup web site Flow Input: -\u003e Map EventString to $trigger.Event (This is the output of SSESubscriber)  Create Flow for Serving Streaming Graph Data Configure flow inputs and outputs No configuration is required here since the data flow comes from SSEEndPoint of Meetup Event Flow directly\nAdd a trigger GraphBuilder_SSE -\u003e SSESubscriber\n  SSE Connection(inbound requests): -\u003e Select “EventServer” for serving streaming data(so now SSEEndPoint connected)\n  Flow Input: -\u003e Map EventString to $trigger.Event (This is the output of SSESubscriber)\n  Incoming Query\n  HTTP GET with resource path /sse/{streamId}\n reply  $flow.queryResult\nsample :\n{\r\"graph\":{\r\"edges\":{},\r\"id\":\"GeographyInfo\",\r\"model\":{\r\"edges\":{\r\"attrTypeMap\":{\"in_Continent\":{}},\r\"directionMap\":{\"in_Continent\":1},\r\"keyMap\":{\"in_Continent\":null},\r\"types\":[\"in_Continent\"],\r\"vertexes\":{\"in_Continent\":[\"City\",\"Continent\"]}\r},\r\"nodes\":{\r\"attrTypeMap\":{\"Continent\":{\"Name\":\"String\"},\"Country\":{\"Country_Code\":\"String\"}},\r\"keyMap\":{\"Continent\":[\"Name\"],\"Country\":[\"Country_Code\"]},\"types\":[\"Country\",\"Continent\"]\r}\r},\r\"modelId\":\"GeographyInfo\",\r\"nodes\":{\r\"Continent_0ecff3229a1a13980689def44b2c66e1\":{\r\"attributes\":{\"Name\":{\"name\":\"Name\",\"type\":\"String\",\"value\":\"North_America\"}},\r\"key\":[\"North_America\"],\r\"keyAttributeName\":[\"Name\"],\r\"type\":\"Continent\"\r},\r\"Country_5181a8acdef7be40dfbf3ec66bee2b20\":{\r\"attributes\":{\"Country_Code\":{\"name\":\"Country_Code\",\"type\":\"String\",\"value\":\"us\"}},\r\"key\":[\"us\"],\r\"keyAttributeName\":[\"Country_Code\"],\r\"type\":\"Country\"\r}\r}\r}\r}\rCreate Flow for Enriching Meetup Graph Configure flow inputs and outputs  input sample  {\r\"Continent\": {\r\"Name\": \"North_America\",\r\"Countries\": [\r\"us\"\r]\r}\r}\rAdd Activity 1 Select GraphBuilder_Builder -\u003e BuildGraph\n Graph Model: -\u003e Select “GeographyInfo” (the connection we created previously) Configure Model: -\u003e Map attributes to input data fields (for nodes and edges)  Add Activity 2 Select GraphBuilder_SSE -\u003e SSEEndPoint\n SSE Connection: -\u003e Select “EventServer” for serving streaming data(the connection we created previously) Avtivity Input 1: set StreamId to “GeographyInfo” (the resource name for client to subscribe) Avtivity Input 2: map required Data object to $activity[BuildGraph].Graph (output of BuildGraph activity)  Add a trigger (Receive HTTP Message)   Setting1: Set Port to any available one (in this sample 9998)\n  Setting2: Set Method to “POST”\n  Setting3: Set Path to “/geography/{Continent}”\n  Output Setting\n  $trigger.pathParams.Continent and $trigger.body\nbody sample :\n{\r\"Countries\": [\r\"us\"\r]\r}\r Flow Input1: Continent.Name map to $trigger.pathParams.Continent Flow Input2: Continent.Countries map to $trigger.body.Countries  Implementation Source stored on GitHub here.\n This example is created in TIBCO Flogo® Enterprise 2.8.1 studio.\n ","excerpt":"This example uses Meetup open event through Meetup API see …","ref":"/labs-graphbuilder-contrib/docs/sample-applications/meetup-event/","title":"Meetup Event"},{"body":" Connector : A Neo4j connector is the component to store your Neo4j server connection information. Activities which connect to the same Neo4j connector would connect to the same Neo4j server instance Neo4jUpsert : A Neo4jUpsert activity consumes the graph entities from BuildGraph activity and inserts/updates them to Neo4j server  ","excerpt":" Connector : A Neo4j connector is the component to store your Neo4j …","ref":"/labs-graphbuilder-contrib/docs/components/graphbuilder-neo4j/","title":"Neo4j"},{"body":"Project GraphBuilder offers an easy and powerful way of loading data from multiple enterprise data sources into a Graph database such as TIBCO® Graph Database in real time in order to materialize the power of the business insights captured in the data.\nPutting the relationships within the data at the forefront allows to traverse and understand complex relationships within the business model in question. Storing data in a graph model allows one to convert complex dynamic data into meaningful business insights.\n","excerpt":"Project GraphBuilder offers an easy and powerful way of loading data …","ref":"/labs-graphbuilder-contrib/docs/sample-applications/","title":"Sample Applications"},{"body":"  Connector : A gremlin connector is the component that stores the Janusgraph server connection information. Activities which connect to the same gremlin connector would connect to the same Janusgraph server instance\n  JanusgraphUpsert : A JanusgraphUpsert activity consumes the graph entities from BuildGraph activity and inserts/updates them to Janusgraph server\n  ","excerpt":"  Connector : A gremlin connector is the component that stores the …","ref":"/labs-graphbuilder-contrib/docs/components/graphbuilder-gremlin/","title":"Gremlin"},{"body":"Create TGDB Connection Create Application Create Flow for querying Metadata Configure flow inputs and outputs  input sample  {\r\"queryType\" : \"\"\r}\r output sample  {\r\"queryResult\": {\r\"content\": {},\r\"success\": true,\r\"error\": {\r\"code\": 101,\r\"message\": \"Not found\"\r}\r}\r}\rAdd activities   Activity 1 : GraphBuilder_TGDB -\u003e TGDBQuery\n  Activity 2 : Default -\u003e Return\n  Add a trigger (Receive HTTP Message)  output  $trigger.pathParams.queryType\n reply  $flow.queryResult\nsample :\n{\r\"queryResult\": {\r\"content\": {},\r\"success\": true,\r\"error\": {\r\"code\": 101,\r\"message\": \"Not found\"\r}\r}\r}\rCreate Flow for Querying Data Configure flow inputs and outputs  input sample  {\r\"queryType\" : \"\",\r\"language\": \"\",\r\"queryString\": \"\",\r\"traversalCondition\": \"\",\r\"endCondition\": \"\",\r\"traversalDepth\": 1\r}\r output sample  {\r\"queryResult\": {\r\"content\": {},\r\"success\": true,\r\"error\": {\r\"code\": 101,\r\"message\": \"Not found\"\r}\r}\r}\rAdd activities   Activity 1 : GraphBuilder_TGDB -\u003e TGDBQuery\n  Activity 2 : Default -\u003e Return\n  Add a trigger (Receive HTTP Message)  output  $trigger.pathParams.queryType and $trigger.body\nsample :\n{\r\"query\": {\r\"language\" : \"tgql\",\r\"queryString\" : \"@nodetype = 'houseMemberType' and memberName = 'Napoleon Bonaparte';\",\r\"traversalCondition\" : \"@edgetype = 'relation' and relation = 'spouse' and @isfromedge = 1 and @degree = 1;\",\r\"endCondition\" : \"\",\r\"traversalDepth\" : 1\r}\r}\r reply  $flow.queryResult\nsample :\n{\r\"queryResult\": {\r\"content\": {},\r\"success\": true,\r\"error\": {\r\"code\": 101,\r\"message\": \"Not found\"\r}\r}\r}\rImplementation Source stored on GitHub here.\n This example is created in TIBCO Flogo® Enterprise 2.8.1 studio.\n ","excerpt":"Create TGDB Connection Create Application Create Flow for querying …","ref":"/labs-graphbuilder-contrib/docs/sample-applications/restful-service/","title":"RESTful Service"},{"body":"  Connector : A SSE connector is a component that stores the sse server (Outbound = false) configuration or remote sse server connection (Outbound = true) information. Activities that connect to the same the SSE connector are connecting to the same SSE service.\n  SSESubscriber : A “SSESubscriber trigger” subscribes to remote sse server then consumes streaming events. The SSE Connector for a subscriber need to be configured as Outbound = true.\n  SSEServer : A “SSEServer trigger” works as an SSE server which serves streaming events. It maintains the incoming connection and requests but won’t generate any data itself. The streaming data comes from another activity called SSEEndPoint. The SSE Connector for a subscriber need to be configured as Outbound = false.\n  SSEEndpoint : A SSEEndpoint activity sits on different flow (a data flow) from SSEServer. It takes input event and streams it to SSEServer. The link between a SSEServer and a SSEEndPoint is that both of them need to connect to the same SSE connector (Outbound = false).\n  ","excerpt":"  Connector : A SSE connector is a component that stores the sse …","ref":"/labs-graphbuilder-contrib/docs/components/graphbuilder-sse/","title":"SSE"},{"body":" FileReader : Read data from single file, files in a folder or file entries in a zip file Accumulator : Accumulate input data then emits it in a batch CSVFileWriter : Write data to file in CSV format CSVParser : Parse data from CSV file based on predefined path then set to a flat tuple JsonDataDecoupler : Extract array data from JSON then emits an array of tuples JsonDeserializer : Convert JSON string to an object JsonParser : Parse data from JSON file based on predefined path then set to a flat tuple JsonSerializer : Convert an object to JSON string  ","excerpt":" FileReader : Read data from single file, files in a folder or file …","ref":"/labs-graphbuilder-contrib/docs/components/graphbuilder-tools/","title":"Tools"},{"body":"This section contains all the user documentation that is needed to understand TIBCO LABS™ Project GraphBuilder\n","excerpt":"This section contains all the user documentation that is needed to …","ref":"/labs-graphbuilder-contrib/docs/","title":"Documentation"},{"body":"","excerpt":"","ref":"/labs-graphbuilder-contrib/index.json","title":""},{"body":"\r\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/about/featured-background_hud062541b21b90529446eee6001de80cd_8365555_960x540_fill_q75_catmullrom_bottom.jpg); }\r@media only screen and (min-width: 1200px) {\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/about/featured-background_hud062541b21b90529446eee6001de80cd_8365555_1920x1080_fill_q75_catmullrom_bottom.jpg); }\r}\r\rProject Graph Builder by TIBCO LABS™\rProject GraphBuilder offers an easy and powerful way to load data from multiple enterprise data sources into TIBCO GraphDB or any graph database of your choice, both in batch and real-time. Leverage the power of relationships to discover new business insights that were previously hidden in your data. Project GraphBuilder makes it simple for you to efficiently traverse, analyze, and access complex relationships across your organization, and convert this dynamic data into a form that is easy to understand and leverage. abc line 2\r--\r\r\r\r\r\r\r\rMore Details about the underlying Product here TIBCO® Graph Database Wiki, on \r\r\r\r\rTIBCO LABS™ is a program designed to provide customers and partners with a mechanism for actively participating in TIBCO’s history of innovation.\rTIBCO has always been at the forefront of innovation, and TIBCO LABS™ allows participants to share in this history by collaboratively building solutions to today’s challenging problems, previewing new capabilities, and accessing emerging technologies in areas such as blockchain, AI / ML and IoT. Through TIBCO LABS™, customers and partners can gain insight into TIBCO’s innovation activities, participate in shaping the form of these activities in the years to come, and benefit from TIBCO’s leadership position in integration and analytics.\r\n\r\r\r\r\n\r\r\r\r\rBSD 3-Clause License \rCopyright © 2020 TIBCO Software Inc. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n  Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n  Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n  Neither the name of TIBCO Software Inc. nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT OWNER AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\r\r\r\r","excerpt":"\r\r#td-cover-block-0 {\rbackground-image: …","ref":"/labs-graphbuilder-contrib/about/","title":"About Project Graph Builder"},{"body":"","excerpt":"","ref":"/labs-graphbuilder-contrib/community/","title":"Community"},{"body":"\r\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/featured-background_hud062541b21b90529446eee6001de80cd_8365555_960x540_fill_q75_catmullrom_top.jpg); }\r@media only screen and (min-width: 1200px) {\r#td-cover-block-0 {\rbackground-image: url(/labs-graphbuilder-contrib/featured-background_hud062541b21b90529446eee6001de80cd_8365555_1920x1080_fill_q75_catmullrom_top.jpg); }\r}\r\rProject GraphBuilder\rLearn More \r\rDownload \r\rLeveraging the power of relationships in your data\n\n\r\r\r\r\r\r\r\rProject GraphBuilder by TIBCO LABS™\nProject GraphBuilder offers an easy and powerful way to load data from multiple enterprise data sources into TIBCO® GraphDB or any graph database of your choice, both in batch and real-time. Leverage the power of relationships to discover new business insights that were previously hidden in your data. Project GraphBuilder makes it simple for you to efficiently traverse, analyze, and access complex relationships across your organization, and convert this dynamic data into a form that is easy to understand and leverage.\n\r\r\r\r\r\rOverview\rBusiness use case, followed by the proposed solution\nRead more …\n\r\r\rComponents\rLearn more about the associated TIBCO products and assets.\nRead more …\n\r\r\rGet Started\rFollow the documentation and get started today!\nRead more …\n\r\r\r--\r\r\r\r\r\r\rContact us!\rReach us for more details, or engage us today !\nRead more …\n\r\r\rContributions welcome!\rWe do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n\r--\r\r\rFollow us on Twitter!\rFor announcement of latest features etc…\nRead more …\n\r\r\r\r","excerpt":"\r\r#td-cover-block-0 {\rbackground-image: …","ref":"/labs-graphbuilder-contrib/","title":"Project Graph Builder"},{"body":"","excerpt":"","ref":"/labs-graphbuilder-contrib/search/","title":"Search Results"}]